{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:24:16.492214Z",
     "start_time": "2025-08-18T19:24:16.486984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms as T\n",
    "import timm\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "import csv\n",
    "\n",
    "SEED = 42\n",
    "ISIC_ROOT = os.path.join('data', 'ISIC')\n",
    "TRAIN_CSV = os.path.join(ISIC_ROOT, 'split_train.csv')\n",
    "VAL_CSV = os.path.join(ISIC_ROOT, 'split_test.csv')\n",
    "LABELS_JSON = os.path.join(ISIC_ROOT, 'labels.json')\n",
    "CKPT_PATH = os.path.join('data/model_weights', 'deit_s_best.pth')\n",
    "\n",
    "LOG_DIR = os.path.join(ISIC_ROOT, 'runs', 'deit_s')\n",
    "CSV_LOG = os.path.join(ISIC_ROOT, 'train_log.csv')\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "BASE_LR = 5e-4\n",
    "WEIGHT_DECAY = 0.05\n",
    "NUM_WORKERS = 0"
   ],
   "id": "e76381da086d4208",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:24:18.485360Z",
     "start_time": "2025-08-18T19:24:18.442237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "class ISICCsvDataset(Dataset):\n",
    "    def __init__(self, csv_path: str, label2idx=None, tfm=None):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'path' not in df.columns or 'label' not in df.columns:\n",
    "            raise ValueError(\"CSV должен содержать столбцы 'path' и 'label'\")\n",
    "        self.paths = df['path'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        if label2idx is None:\n",
    "            uniq = sorted(pd.unique(self.labels).tolist())\n",
    "            label2idx = {lbl: i for i, lbl in enumerate(uniq)}\n",
    "        self.label2idx = label2idx\n",
    "        self.tfm = tfm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        y_str = self.labels[idx]\n",
    "        y = self.label2idx[y_str]\n",
    "        with Image.open(p) as img:\n",
    "            img = img.convert('RGB')\n",
    "        if self.tfm:\n",
    "            img = self.tfm(img)\n",
    "        return img, y\n",
    "\n",
    "\n",
    "def build_transforms(img_size=224):\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_tfm = T.Compose([\n",
    "        T.RandomResizedCrop(img_size, scale=(0.7, 1.0), ratio=(0.75, 1.33)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std),\n",
    "    ])\n",
    "    val_tfm = T.Compose([\n",
    "        T.Resize(int(img_size * 1.14)),\n",
    "        T.CenterCrop(img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std),\n",
    "    ])\n",
    "    return train_tfm, val_tfm\n",
    "\n",
    "\n",
    "def make_weighted_sampler(labels_idx, num_classes):\n",
    "    counts = np.bincount(labels_idx, minlength=num_classes).astype(np.float32)\n",
    "    inv = 1.0 / np.maximum(counts, 1.0)\n",
    "    weights = [inv[y] for y in labels_idx]\n",
    "    return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True), counts\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return total_loss / max(total, 1), total_correct / max(total, 1)\n",
    "\n",
    "\n",
    "set_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "train_tfm, val_tfm = build_transforms(IMG_SIZE)\n",
    "\n",
    "tmp_train = pd.read_csv(TRAIN_CSV)\n",
    "uniq_labels = sorted(pd.unique(tmp_train['label']).tolist())\n",
    "label2idx = {lbl: i for i, lbl in enumerate(uniq_labels)}\n",
    "with open(LABELS_JSON, 'w', encoding='utf-8') as f:\n",
    "    json.dump(label2idx, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "train_ds = ISICCsvDataset(TRAIN_CSV, label2idx=label2idx, tfm=train_tfm)\n",
    "val_ds = ISICCsvDataset(VAL_CSV, label2idx=label2idx, tfm=val_tfm)\n",
    "num_classes = len(label2idx)\n",
    "print(f'Классов: {num_classes} -> {uniq_labels}')\n",
    "\n",
    "train_labels_idx = [label2idx[l] for l in tmp_train['label'].tolist()]\n",
    "sampler, class_counts = make_weighted_sampler(train_labels_idx, num_classes)\n",
    "print('Распределение классов (train):', class_counts.tolist())"
   ],
   "id": "afb5177049519962",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Классов: 7 -> ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
      "Распределение классов (train): [262.0, 411.0, 879.0, 92.0, 890.0, 5364.0, 114.0]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:24:21.863862Z",
     "start_time": "2025-08-18T19:24:21.120754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pin = device.type == 'cuda'\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "    num_workers=NUM_WORKERS, pin_memory=pin, persistent_workers=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=pin, persistent_workers=False\n",
    ")\n",
    "\n",
    "model = timm.create_model('deit_small_patch16_224', pretrained=True, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))\n",
    "\n",
    "writer = SummaryWriter(LOG_DIR)\n",
    "best_acc = 0.0\n",
    "global_step = 0\n",
    "\n",
    "if not os.path.exists(CSV_LOG):\n",
    "    with open(CSV_LOG, 'w', newline='', encoding='utf-8') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['epoch', 'train_loss', 'val_loss', 'val_acc', 'lr'])\n"
   ],
   "id": "b220c2f6a7d64a0b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-18T19:55:34.676128Z",
     "start_time": "2025-08-18T19:24:48.221577Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_acc = 0.0\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    seen = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{EPOCHS}', leave=False)\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # accumulate loss\n",
    "        bs = y.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        seen += bs\n",
    "\n",
    "        # batch accuracy\n",
    "        preds = logits.argmax(1)\n",
    "        correct = (preds == y).sum().item()\n",
    "        running_correct += correct\n",
    "        batch_acc = correct / bs\n",
    "\n",
    "        # log batch metrics\n",
    "        writer.add_scalar('train/batch_loss', loss.item(), global_step)\n",
    "        writer.add_scalar('train/batch_acc', batch_acc, global_step)\n",
    "        writer.add_scalar('train/lr', optimizer.param_groups[0]['lr'], global_step)\n",
    "        pbar.set_postfix(batch_loss=f'{loss.item():.4f}',\n",
    "                         batch_acc=f'{batch_acc:.4f}',\n",
    "                         lr=f\"{optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        global_step += 1\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss = running_loss / max(seen, 1)\n",
    "    train_acc = running_correct / max(seen, 1)\n",
    "\n",
    "    # validation\n",
    "    val_loss, val_acc = evaluate(model, val_loader, device, criterion)\n",
    "\n",
    "    # log epoch metrics\n",
    "    writer.add_scalar('train/epoch_loss', train_loss, epoch)\n",
    "    writer.add_scalar('train/epoch_acc', train_acc, epoch)\n",
    "    writer.add_scalar('val/loss', val_loss, epoch)\n",
    "    writer.add_scalar('val/acc', val_acc, epoch)\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | '\n",
    "          f'train_loss={train_loss:.4f}  train_acc={train_acc:.4f}  '\n",
    "          f'val_loss={val_loss:.4f}  val_acc={val_acc:.4f}  '\n",
    "          f'lr={scheduler.get_last_lr()[0]:.2e}')\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'label2idx': label2idx,\n",
    "            'epoch': epoch,\n",
    "            'val_acc': val_acc\n",
    "        }, CKPT_PATH)\n",
    "        print(f'Save best weights -> {CKPT_PATH}')\n",
    "\n",
    "print(f'Best val_acc: {best_acc:.4f}')\n",
    "writer.close()"
   ],
   "id": "c55df1092341013",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=1.4073  train_acc=0.4472  val_loss=1.0675  val_acc=0.5632  lr=4.97e-04\n",
      "Save best weights -> data/model_weights\\deit_s_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | train_loss=1.0272  train_acc=0.6090  val_loss=0.7592  val_acc=0.7284  lr=4.88e-04\n",
      "Save best weights -> data/model_weights\\deit_s_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | train_loss=0.8149  train_acc=0.6935  val_loss=0.8974  val_acc=0.6500  lr=4.73e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | train_loss=0.7501  train_acc=0.7169  val_loss=0.7428  val_acc=0.7424  lr=4.52e-04\n",
      "Save best weights -> data/model_weights\\deit_s_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | train_loss=0.6669  train_acc=0.7469  val_loss=0.9142  val_acc=0.6191  lr=4.27e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | train_loss=0.5994  train_acc=0.7733  val_loss=0.6421  val_acc=0.7439  lr=3.97e-04\n",
      "Save best weights -> data/model_weights\\deit_s_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | train_loss=0.5643  train_acc=0.7820  val_loss=0.8439  val_acc=0.6520  lr=3.63e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | train_loss=0.4956  train_acc=0.8142  val_loss=0.9573  val_acc=0.6405  lr=3.27e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | train_loss=0.4381  train_acc=0.8339  val_loss=0.6943  val_acc=0.7269  lr=2.89e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | train_loss=0.3965  train_acc=0.8474  val_loss=0.8342  val_acc=0.6715  lr=2.50e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | train_loss=0.3626  train_acc=0.8640  val_loss=0.7037  val_acc=0.7504  lr=2.11e-04\n",
      "Save best weights -> data/model_weights\\deit_s_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | train_loss=0.3046  train_acc=0.8868  val_loss=0.8006  val_acc=0.7149  lr=1.73e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | train_loss=0.2497  train_acc=0.9031  val_loss=0.6754  val_acc=0.7678  lr=1.37e-04\n",
      "Save best weights -> data/model_weights\\deit_s_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | train_loss=0.2040  train_acc=0.9237  val_loss=0.6764  val_acc=0.7693  lr=1.03e-04\n",
      "Save best weights -> data/model_weights\\deit_s_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | train_loss=0.1792  train_acc=0.9321  val_loss=0.6349  val_acc=0.7888  lr=7.32e-05\n",
      "Save best weights -> data/model_weights\\deit_s_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 016 | train_loss=0.1459  train_acc=0.9457  val_loss=0.6102  val_acc=0.8168  lr=4.77e-05\n",
      "Save best weights -> data/model_weights\\deit_s_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 017 | train_loss=0.1228  train_acc=0.9546  val_loss=0.6519  val_acc=0.8058  lr=2.72e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 018 | train_loss=0.1068  train_acc=0.9612  val_loss=0.6532  val_acc=0.7968  lr=1.22e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 019 | train_loss=0.0866  train_acc=0.9674  val_loss=0.6504  val_acc=0.8008  lr=3.08e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020 | train_loss=0.0838  train_acc=0.9703  val_loss=0.6575  val_acc=0.7973  lr=0.00e+00\n",
      "Best val_acc: 0.8168\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1032d814b1efe803"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
