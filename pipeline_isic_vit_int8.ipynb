{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:52.710320Z",
     "start_time": "2025-08-19T20:21:52.705797Z"
    }
   },
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import platform\n",
    "import psutil\n",
    "import warnings\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms as T\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, roc_auc_score,\n",
    "    precision_recall_fscore_support, confusion_matrix\n",
    ")\n",
    "\n",
    "import timm\n",
    "\n",
    "from EMA_for_weights import EMA\n",
    "from wqat import LinearWQAT"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:53.325872Z",
     "start_time": "2025-08-19T20:21:53.320041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== Константы/пути ========\n",
    "SEED = 42\n",
    "ISIC_ROOT = os.path.join('data', 'ISIC')\n",
    "TRAIN_CSV = os.path.join(ISIC_ROOT, 'split_train.csv')\n",
    "VAL_CSV = os.path.join(ISIC_ROOT, 'split_val.csv')          # будет создан при первом запуске\n",
    "TEST_CSV = os.path.join(ISIC_ROOT, 'split_test.csv')         # финальная оценка (без аугм., 1 проход)\n",
    "LABELS_JSON = os.path.join(ISIC_ROOT, 'labels.json')\n",
    "\n",
    "WEIGHTS_DIR = os.path.join('data', 'model_weights')\n",
    "RESULTS_DIR = os.path.join('data', 'results')\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "CKPT_TEACHER = os.path.join(WEIGHTS_DIR, 'deit_s_best.pth')\n",
    "CKPT_STUDENT = os.path.join(WEIGHTS_DIR, 'student_best.pth')\n",
    "CKPT_STUDENT_EMA = os.path.join(WEIGHTS_DIR, 'student_best_ema.pth')\n",
    "CKPT_STUDENT_INT8 = os.path.join(WEIGHTS_DIR, 'student_best_int8.pth')\n",
    "CKPT_STUDENT_EMA_INT8 = os.path.join(WEIGHTS_DIR, 'student_best_ema_int8.pth')\n",
    "\n",
    "# QAT-lite\n",
    "CKPT_STUDENT_QATL_FP32 = os.path.join(WEIGHTS_DIR, 'student_best_qatlite.pth')\n",
    "CKPT_STUDENT_QATL_INT8 = os.path.join(WEIGHTS_DIR, 'student_best_qatlite_int8.pth')\n",
    "\n",
    "# HParams\n",
    "IMG_SIZE = 224\n",
    "BATCH_TRAIN = 32\n",
    "BATCH_EVAL = 64\n",
    "NUM_WORKERS = 0  # Windows\n",
    "EPOCHS = 15\n",
    "BASE_LR = 3e-4\n",
    "WEIGHT_DECAY = 0.05\n",
    "KD_T = 4.0\n",
    "KD_ALPHA = 0.7\n",
    "\n",
    "# QAT-lite hparams\n",
    "QAT_EPOCHS = 5\n",
    "QAT_LR = 3e-5\n",
    "QAT_WD = 0.0\n",
    "QAT_PER_CHANNEL = True\n",
    "\n",
    "# CPU quant backend\n",
    "torch.backends.quantized.engine = 'fbgemm'"
   ],
   "id": "4b1afc5e433eb00d",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:53.930632Z",
     "start_time": "2025-08-19T20:21:53.923569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== Утилиты ========\n",
    "def set_global_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.benchmark = False  # воспроизводимость\n",
    "\n",
    "\n",
    "def ensure_val_split(train_csv: str, val_csv: str, val_size=0.1, seed=42):\n",
    "    if os.path.isfile(val_csv):\n",
    "        return\n",
    "    df = pd.read_csv(train_csv)\n",
    "    if not {'path', 'label'} <= set(df.columns):\n",
    "        raise ValueError(\"Ожидаются столбцы 'path' и 'label' в split_train.csv\")\n",
    "    idx = np.arange(len(df))\n",
    "    y = df['label'].values\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=val_size, random_state=seed)\n",
    "    tr_idx, val_idx = next(sss.split(idx, y))\n",
    "    df_val = df.iloc[val_idx].copy()\n",
    "    df_val.to_csv(val_csv, index=False)\n",
    "    print(f'Создан валид. сплит: {val_csv} (n={len(df_val)})')\n",
    "\n",
    "\n",
    "def system_info() -> Dict[str, str]:\n",
    "    cpu = platform.processor()\n",
    "    if not cpu:\n",
    "        try:\n",
    "            import cpuinfo  # type: ignore\n",
    "            cpu = cpuinfo.get_cpu_info().get('brand_raw', '')\n",
    "        except Exception:\n",
    "            cpu = 'unknown'\n",
    "    return {\n",
    "        'python': platform.python_version(),\n",
    "        'pytorch': torch.__version__,\n",
    "        'os': platform.platform(),\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'cpu': cpu,\n",
    "        'quant_backend': getattr(torch.backends.quantized, 'engine', None),\n",
    "        'inference_backend': 'torch-eager'\n",
    "    }\n",
    "\n",
    "\n",
    "def count_params(m: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in m.parameters())\n",
    "\n",
    "\n",
    "def count_flops(m: nn.Module, img_size=224) -> Optional[int]:\n",
    "    try:\n",
    "        from ptflops import get_model_complexity_info  # type: ignore\n",
    "        m_eval = copy.deepcopy(m).eval().cpu()\n",
    "        with torch.no_grad():\n",
    "            macs, _ = get_model_complexity_info(\n",
    "                m_eval, (3, img_size, img_size), as_strings=False, print_per_layer_stat=False\n",
    "            )\n",
    "        return int(macs * 2)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def state_dict_size_mb(state_dict: Dict[str, torch.Tensor]) -> float:\n",
    "    buf = io.BytesIO()\n",
    "    torch.save(state_dict, buf)\n",
    "    return buf.tell() / (1024.0 * 1024.0)\n"
   ],
   "id": "8699e0a0c3d86f0c",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:54.547561Z",
     "start_time": "2025-08-19T20:21:54.541096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== Данные ========\n",
    "class ISICCsvDataset(Dataset):\n",
    "    def __init__(self, csv_path: str, label2idx=None, tfm=None):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'path' not in df.columns or 'label' not in df.columns:\n",
    "            raise ValueError(\"CSV должен содержать столбцы 'path' и 'label'\")\n",
    "        self.paths = df['path'].tolist()\n",
    "        self.labels_str = df['label'].tolist()\n",
    "        if label2idx is None:\n",
    "            uniq = sorted(pd.unique(self.labels_str).tolist())\n",
    "            label2idx = {s: i for i, s in enumerate(uniq)}\n",
    "        self.label2idx = label2idx\n",
    "        self.labels = [self.label2idx[s] for s in self.labels_str]\n",
    "        self.tfm = tfm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        y = self.labels[idx]\n",
    "        with Image.open(p) as img:\n",
    "            img = img.convert('RGB')\n",
    "        if self.tfm:\n",
    "            img = self.tfm(img)\n",
    "        return img, y\n",
    "\n",
    "\n",
    "def build_transforms(img_size=224):\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_tfm = T.Compose([\n",
    "        T.RandomResizedCrop(img_size, scale=(0.7, 1.0), ratio=(0.75, 1.33)),\n",
    "        T.RandomHorizontalFlip(0.5),\n",
    "        T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std),\n",
    "    ])\n",
    "    val_tfm = T.Compose([\n",
    "        T.Resize(int(img_size * 1.14)),\n",
    "        T.CenterCrop(img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std),\n",
    "    ])\n",
    "    return train_tfm, val_tfm\n",
    "\n",
    "\n",
    "def make_weighted_sampler(labels_idx: List[int], num_classes: int):\n",
    "    counts = np.bincount(labels_idx, minlength=num_classes).astype(np.float32)\n",
    "    inv = 1.0 / np.maximum(counts, 1.0)\n",
    "    weights = [inv[y] for y in labels_idx]\n",
    "    return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True), counts\n"
   ],
   "id": "9501b3236f322dcc",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:55.514843Z",
     "start_time": "2025-08-19T20:21:55.506671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== Модели ========\n",
    "def build_teacher(num_classes: int) -> nn.Module:\n",
    "    # DeiT-S\n",
    "    m = timm.create_model('deit_small_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "    if os.path.isfile(CKPT_TEACHER):\n",
    "        ckpt = torch.load(CKPT_TEACHER, map_location='cpu')\n",
    "        sd = ckpt['model'] if isinstance(ckpt, dict) and 'model' in ckpt else ckpt\n",
    "        m.load_state_dict(sd, strict=True)\n",
    "    else:\n",
    "        warnings.warn('CKPT_TEACHER не найден — используем timm pretrained head, num_classes адаптирован')\n",
    "        m = timm.create_model('deit_small_patch16_224', pretrained=True, num_classes=num_classes)\n",
    "    m.eval()\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad_(False)\n",
    "    return m\n",
    "\n",
    "\n",
    "def build_student(num_classes: int, pretrained=True) -> nn.Module:\n",
    "    return timm.create_model('deit_tiny_patch16_224', pretrained=pretrained, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def build_baselines(num_classes: int) -> Dict[str, nn.Module]:\n",
    "    names = {\n",
    "        'resnet18': 'resnet18',\n",
    "        'mobilenetv3': 'mobilenetv3_large_100',\n",
    "        'convnext_tiny': 'convnext_tiny',\n",
    "    }\n",
    "    out = {}\n",
    "    for tag, name in names.items():\n",
    "        try:\n",
    "            out[f'{tag}_fp32'] = timm.create_model(name, pretrained=True, num_classes=num_classes)\n",
    "        except Exception as e:\n",
    "            print(f'Бейзлайн {name} пропущен: {e}')\n",
    "    return out\n",
    "\n",
    "\n",
    "def to_int8_dynamic(fp32_model: nn.Module) -> nn.Module:\n",
    "    # Только nn.Linear для ViT/DeiT и большинства CNN голов\n",
    "    return torch.ao.quantization.quantize_dynamic(copy.deepcopy(fp32_model), {nn.Linear}, dtype=torch.qint8)\n"
   ],
   "id": "64b5eb0e5dd0004c",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:56.129710Z",
     "start_time": "2025-08-19T20:21:56.120868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== Потери/оценка ========\n",
    "def kd_loss(student_logits, teacher_logits, labels, T=4.0, alpha=0.7):\n",
    "    soft = F.kl_div(\n",
    "        F.log_softmax(student_logits / T, dim=1),\n",
    "        F.softmax(teacher_logits / T, dim=1),\n",
    "        reduction='batchmean'\n",
    "    ) * (T * T)\n",
    "    hard = F.cross_entropy(student_logits, labels)\n",
    "    return alpha * soft + (1.0 - alpha) * hard\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_loss_acc(model: nn.Module, loader: DataLoader, device) -> Tuple[float, float]:\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    model.eval().to(device)\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss = ce(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return total_loss / max(1, total), correct / max(1, total)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_logits_labels(model: nn.Module, loader: DataLoader, device=torch.device('cpu')):\n",
    "    model.eval().to(device)\n",
    "    lg, lb = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        lg.append(model(x).cpu())\n",
    "        lb.append(y.cpu())\n",
    "    return torch.cat(lg, 0), torch.cat(lb, 0)\n",
    "\n",
    "\n",
    "def compute_metrics(logits: torch.Tensor, labels: torch.Tensor, class_names: Optional[List[str]] = None) -> Dict:\n",
    "    y_true = labels.numpy()\n",
    "    y_prob = F.softmax(logits, dim=1).numpy()\n",
    "    y_pred = y_prob.argmax(1)\n",
    "    nc = logits.size(1)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    try:\n",
    "        if nc == 2:\n",
    "            roc_macro = roc_auc_score(y_true, y_prob[:, 1])\n",
    "        else:\n",
    "            roc_macro = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')\n",
    "    except Exception:\n",
    "        roc_macro = float('nan')\n",
    "\n",
    "    prec_c, rec_c, f1_c, supp_c = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=np.arange(nc), average=None, zero_division=0\n",
    "    )\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(nc))\n",
    "    per_class = []\n",
    "    for i in range(nc):\n",
    "        name = class_names[i] if (class_names and i < len(class_names)) else f'class_{i}'\n",
    "        per_class.append({\n",
    "            'class': name, 'precision': float(prec_c[i]), 'recall': float(rec_c[i]),\n",
    "            'f1': float(f1_c[i]), 'support': int(supp_c[i])\n",
    "        })\n",
    "    return {\n",
    "        'accuracy': float(acc),\n",
    "        'macro_f1': float(macro_f1),\n",
    "        'roc_auc_macro': float(roc_macro) if not math.isnan(roc_macro) else float('nan'),\n",
    "        'per_class': per_class,\n",
    "        'confusion_matrix': cm.astype(int).tolist(),\n",
    "    }\n"
   ],
   "id": "af37c57fec3119b",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:56.835084Z",
     "start_time": "2025-08-19T20:21:56.828579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== Обучение KD + EMA ========\n",
    "def train_kd_ema(student: nn.Module, teacher: nn.Module,\n",
    "                 train_loader: DataLoader, val_loader: DataLoader,\n",
    "                 device, epochs=15, base_lr=3e-4, weight_decay=0.05,\n",
    "                 kd_T=4.0, kd_alpha=0.7,\n",
    "                 ckpt_student=CKPT_STUDENT, ckpt_student_ema=CKPT_STUDENT_EMA) -> Tuple[str, str]:\n",
    "    ema = EMA(student, decay=0.999)\n",
    "    optimizer = torch.optim.AdamW(student.parameters(), lr=base_lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))\n",
    "\n",
    "    best_acc, best_acc_ema = 0.0, 0.0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        student.train()\n",
    "        run_loss, run_correct, seen = 0.0, 0, 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                t_logits = teacher(x)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n",
    "                s_logits = student(x)\n",
    "                loss = kd_loss(s_logits, t_logits, y, T=kd_T, alpha=kd_alpha)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            ema.update(student)\n",
    "\n",
    "            bs = y.size(0)\n",
    "            seen += bs\n",
    "            run_loss += loss.item() * bs\n",
    "            run_correct += (s_logits.argmax(1) == y).sum().item()\n",
    "        scheduler.step()\n",
    "\n",
    "        tr_loss = run_loss / max(1, seen)\n",
    "        tr_acc = run_correct / max(1, seen)\n",
    "        v_loss, v_acc = evaluate_loss_acc(student, val_loader, device)\n",
    "        v_loss_e, v_acc_e = evaluate_loss_acc(ema.ema_model, val_loader, device)\n",
    "        print(f'Epoch {epoch:03d} | train: loss={tr_loss:.4f} acc={tr_acc:.4f} | '\n",
    "              f'val: s=({v_loss:.4f},{v_acc:.4f}) ema=({v_loss_e:.4f},{v_acc_e:.4f})')\n",
    "\n",
    "        if v_acc > best_acc:\n",
    "            best_acc = v_acc\n",
    "            torch.save({'model': student.state_dict()}, ckpt_student)\n",
    "        if v_acc_e > best_acc_ema:\n",
    "            best_acc_ema = v_acc_e\n",
    "            torch.save({'model': ema.ema_model.state_dict()}, ckpt_student_ema)\n",
    "\n",
    "    print(f'Best val acc: student={best_acc:.4f} | ema={best_acc_ema:.4f}')\n",
    "    return ckpt_student, ckpt_student_ema\n"
   ],
   "id": "d8b5d37c4e9d2265",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:57.628017Z",
     "start_time": "2025-08-19T20:21:57.616492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== QAT-lite ========\n",
    "def wrap_linears_with_wqat(module: nn.Module, per_channel=True) -> nn.Module:\n",
    "    for name, child in list(module.named_children()):\n",
    "        if isinstance(child, nn.Linear):\n",
    "            setattr(module, name, LinearWQAT(child, per_channel=per_channel))\n",
    "        else:\n",
    "            wrap_linears_with_wqat(child, per_channel=per_channel)\n",
    "    return module\n",
    "\n",
    "\n",
    "def unwrap_wqat_to_linear(module: nn.Module) -> nn.Module:\n",
    "    for name, child in list(module.named_children()):\n",
    "        if isinstance(child, LinearWQAT):\n",
    "            base = nn.Linear(child.in_features, child.out_features, bias=child.has_bias)\n",
    "            with torch.no_grad():\n",
    "                base.weight.copy_(child.weight)\n",
    "                if child.has_bias:\n",
    "                    base.bias.copy_(child.bias)\n",
    "            setattr(module, name, base)\n",
    "        else:\n",
    "            unwrap_wqat_to_linear(child)\n",
    "    return module\n",
    "\n",
    "\n",
    "def train_qat_lite(student_base: nn.Module, teacher: nn.Module,\n",
    "                   train_loader: DataLoader, val_loader: DataLoader,\n",
    "                   device, epochs=5, lr=3e-5, wd=0.0, per_channel=True,\n",
    "                   ckpt_qat_fp32=CKPT_STUDENT_QATL_FP32,\n",
    "                   ckpt_qat_int8=CKPT_STUDENT_QATL_INT8) -> Tuple[str, str]:\n",
    "    student_qat = wrap_linears_with_wqat(copy.deepcopy(student_base), per_channel=per_channel).to(device)\n",
    "    opt = torch.optim.AdamW(student_qat.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "    teacher.eval().to(device)\n",
    "    for p in teacher.parameters():\n",
    "        p.requires_grad_(False)\n",
    "\n",
    "    print(f'QAT-lite: epochs={epochs}, lr={lr}, wd={wd}, per_channel={per_channel}')\n",
    "    for ep in range(1, epochs + 1):\n",
    "        student_qat.train()\n",
    "        run_loss, seen = 0.0, 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.no_grad():\n",
    "                t_logits = teacher(x)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            s_logits = student_qat(x)\n",
    "            loss = kd_loss(s_logits, t_logits, y, T=KD_T, alpha=KD_ALPHA)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            run_loss += loss.item() * y.size(0)\n",
    "            seen += y.size(0)\n",
    "        v_loss, v_acc = evaluate_loss_acc(student_qat, val_loader, device)\n",
    "        print(f'QAT {ep:02d}/{epochs} | train_loss={run_loss/max(1,seen):.4f} | val_loss={v_loss:.4f} val_acc={v_acc:.4f}')\n",
    "\n",
    "    # Unwrap to Linear and save FP32\n",
    "    student_qat_fp32 = unwrap_wqat_to_linear(copy.deepcopy(student_qat).cpu())\n",
    "    torch.save({'model': student_qat_fp32.state_dict()}, ckpt_qat_fp32)\n",
    "\n",
    "    # INT8 (dynamic)\n",
    "    student_qat_int8 = to_int8_dynamic(student_qat_fp32)\n",
    "    torch.save({'model': student_qat_int8.state_dict()}, ckpt_qat_int8)\n",
    "    return ckpt_qat_fp32, ckpt_qat_int8\n"
   ],
   "id": "1138cead9191a3bf",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:58.452333Z",
     "start_time": "2025-08-19T20:21:58.445620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== CPU-бенчмарк ========\n",
    "def cache_batches(loader: DataLoader, limit: Optional[int] = None):\n",
    "    cached = []\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        cached.append((x.cpu(), y))\n",
    "        if limit is not None and i + 1 >= limit:\n",
    "            break\n",
    "    return cached\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_cpu(model: nn.Module, cached_batches,\n",
    "                  warmup=50, measure=100, reps=5) -> Dict[str, float]:\n",
    "    proc = psutil.Process(os.getpid())\n",
    "    model.eval().cpu()\n",
    "    lat_ms = []\n",
    "    total_imgs, total_time = 0, 0.0\n",
    "    peak = proc.memory_info().rss\n",
    "\n",
    "    if not cached_batches:\n",
    "        raise RuntimeError('Нет батчей для бенчмарка')\n",
    "    nb = len(cached_batches)\n",
    "\n",
    "    # Warmup\n",
    "    j = 0\n",
    "    for _ in range(warmup):\n",
    "        x, _ = cached_batches[j % nb]; j += 1\n",
    "        _ = model(x)\n",
    "        peak = max(peak, proc.memory_info().rss)\n",
    "\n",
    "    # Measure\n",
    "    j = 0\n",
    "    for _ in range(reps):\n",
    "        for _ in range(measure):\n",
    "            x, _ = cached_batches[j % nb]; j += 1\n",
    "            t0 = time.perf_counter()\n",
    "            _ = model(x)\n",
    "            dt = time.perf_counter() - t0\n",
    "            lat_ms.append(dt * 1e3)\n",
    "            total_imgs += x.size(0)\n",
    "            total_time += dt\n",
    "            peak = max(peak, proc.memory_info().rss)\n",
    "\n",
    "    lat = np.asarray(lat_ms, dtype=np.float64)\n",
    "    p50 = float(np.percentile(lat, 50))\n",
    "    p90 = float(np.percentile(lat, 90))\n",
    "    thr = float(total_imgs / total_time) if total_time > 0 else float('nan')\n",
    "    peak_mb = peak / (1024.0 * 1024.0)\n",
    "    size_mb = state_dict_size_mb(model.state_dict()) if hasattr(model, 'state_dict') else float('nan')\n",
    "    return {'p50_ms': p50, 'p90_ms': p90, 'thr_img_s': thr, 'peak_ram_mb': peak_mb, 'size_mb': size_mb}\n",
    "\n"
   ],
   "id": "f6187f1e0bab33d7",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:21:59.303925Z",
     "start_time": "2025-08-19T20:21:59.300238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ExportOnlyLogits(nn.Module):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        if isinstance(out, torch.Tensor):\n",
    "            return out\n",
    "        if isinstance(out, (list, tuple)):\n",
    "            for v in out:\n",
    "                if isinstance(v, torch.Tensor) and v.dim() == 2:\n",
    "                    return v\n",
    "        if isinstance(out, dict):\n",
    "            for v in out.values():\n",
    "                if isinstance(v, torch.Tensor) and v.dim() == 2:\n",
    "                    return v\n",
    "        raise RuntimeError('Экспорт: forward не вернул тензор с логитами.')"
   ],
   "id": "c6fe2582db578850",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:22:00.073551Z",
     "start_time": "2025-08-19T20:22:00.068079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== Повторы (k) для mean±std ========\n",
    "def k_repeats_eval(model: nn.Module, base_csv: str, dataset_cls, label2idx, tfm, k=5, seed=42):\n",
    "    df = pd.read_csv(base_csv)\n",
    "    X = df['path'].values\n",
    "    y = df['label'].values\n",
    "    idx = np.arange(len(df))\n",
    "    sss = StratifiedShuffleSplit(n_splits=k, test_size=0.5, random_state=seed)\n",
    "    recs = []\n",
    "    for _, val_idx in sss.split(idx, y):\n",
    "        tmp = df.iloc[val_idx].copy()\n",
    "        tmp_csv = os.path.join(ISIC_ROOT, '_tmp_val.csv')\n",
    "        tmp.to_csv(tmp_csv, index=False)\n",
    "        ds = dataset_cls(tmp_csv, label2idx=label2idx, tfm=tfm)\n",
    "        ld = DataLoader(ds, batch_size=BATCH_EVAL, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        lg, lb = collect_logits_labels(model, ld, device=torch.device('cpu'))\n",
    "        m = compute_metrics(lg, lb, None)\n",
    "        recs.append(m)\n",
    "        os.remove(tmp_csv)\n",
    "    def _agg(key):\n",
    "        vals = [r[key] for r in recs if isinstance(r[key], float) and not math.isnan(r[key])]\n",
    "        return (float(np.mean(vals)), float(np.std(vals))) if vals else (float('nan'), float('nan'))\n",
    "    return {'acc': _agg('accuracy'), 'macro_f1': _agg('macro_f1'), 'roc_auc_macro': _agg('roc_auc_macro')}\n"
   ],
   "id": "fca4873916b415b3",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:22:00.886563Z",
     "start_time": "2025-08-19T20:22:00.881512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======== Главный сценарий ========\n",
    "print('System:', system_info())\n",
    "set_global_seed(SEED)\n",
    "ensure_val_split(TRAIN_CSV, VAL_CSV, val_size=0.1, seed=SEED)\n"
   ],
   "id": "9b8bdcadff91f5a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: {'python': '3.11.0', 'pytorch': '2.7.1+cu118', 'os': 'Windows-10-10.0.26100-SP0', 'device': 'cuda', 'cpu': 'Intel64 Family 6 Model 151 Stepping 2, GenuineIntel', 'quant_backend': 'fbgemm', 'inference_backend': 'torch-eager'}\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T20:22:01.916191Z",
     "start_time": "2025-08-19T20:22:01.873299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# labels\n",
    "with open(LABELS_JSON, 'r', encoding='utf-8') as f:\n",
    "    label2idx = json.load(f)\n",
    "idx2label = {v: k for k, v in label2idx.items()}\n",
    "num_classes = len(label2idx)\n",
    "\n",
    "# data\n",
    "train_tfm, val_tfm = build_transforms(IMG_SIZE)\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_labels_idx = [label2idx[s] for s in train_df['label'].tolist()]\n",
    "sampler, cls_counts = make_weighted_sampler(train_labels_idx, num_classes)\n",
    "\n",
    "train_ds = ISICCsvDataset(TRAIN_CSV, label2idx=label2idx, tfm=train_tfm)\n",
    "val_ds = ISICCsvDataset(VAL_CSV, label2idx=label2idx, tfm=val_tfm)\n",
    "test_ds = ISICCsvDataset(TEST_CSV, label2idx=label2idx, tfm=val_tfm) if os.path.isfile(TEST_CSV) else None\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pin = device.type == 'cuda'\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, sampler=sampler,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=pin)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=pin)\n",
    "test_loader = None\n",
    "if test_ds is not None:\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
    "                             num_workers=NUM_WORKERS, pin_memory=pin)\n",
    "\n",
    "print('Train class counts:', cls_counts.tolist())\n",
    "\n"
   ],
   "id": "1352d59494254103",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts: [262.0, 411.0, 879.0, 92.0, 890.0, 5364.0, 114.0]\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:08:24.085563Z",
     "start_time": "2025-08-19T20:22:02.688681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# teacher / student\n",
    "teacher = build_teacher(num_classes).to(device).eval()\n",
    "student = build_student(num_classes, pretrained=True).to(device)\n",
    "\n",
    "# KD+EMA training\n",
    "s_ckpt, s_ema_ckpt = train_kd_ema(\n",
    "    student, teacher, train_loader, val_loader, device,\n",
    "    epochs=EPOCHS, base_lr=BASE_LR, weight_decay=WEIGHT_DECAY,\n",
    "    kd_T=KD_T, kd_alpha=KD_ALPHA,\n",
    "    ckpt_student=CKPT_STUDENT, ckpt_student_ema=CKPT_STUDENT_EMA\n",
    ")\n",
    "\n",
    "# Load best FP32 models\n",
    "student_fp32 = build_student(num_classes, pretrained=False)\n",
    "student_fp32.load_state_dict(torch.load(s_ckpt, map_location='cpu')['model'], strict=True)\n",
    "student_ema_fp32 = build_student(num_classes, pretrained=False)\n",
    "student_ema_fp32.load_state_dict(torch.load(s_ema_ckpt, map_location='cpu')['model'], strict=True)\n",
    "\n",
    "# INT8 (PTQ dynamic)\n",
    "student_int8 = to_int8_dynamic(student_fp32)\n",
    "student_ema_int8 = to_int8_dynamic(student_ema_fp32)\n",
    "torch.save({'model': student_int8.state_dict()}, CKPT_STUDENT_INT8)\n",
    "torch.save({'model': student_ema_int8.state_dict()}, CKPT_STUDENT_EMA_INT8)\n",
    "\n",
    "# QAT-lite (из EMA)\n",
    "qatl_fp32_path, qatl_int8_path = train_qat_lite(\n",
    "    student_base=student_ema_fp32, teacher=teacher,\n",
    "    train_loader=train_loader, val_loader=val_loader, device=device,\n",
    "    epochs=QAT_EPOCHS, lr=QAT_LR, wd=QAT_WD, per_channel=QAT_PER_CHANNEL,\n",
    "    ckpt_qat_fp32=CKPT_STUDENT_QATL_FP32, ckpt_qat_int8=CKPT_STUDENT_QATL_INT8\n",
    ")\n",
    "student_qatl_fp32 = build_student(num_classes, pretrained=False)\n",
    "student_qatl_fp32.load_state_dict(torch.load(qatl_fp32_path, map_location='cpu')['model'], strict=True)\n",
    "student_qatl_int8 = build_student(num_classes, pretrained=False)\n",
    "student_qatl_int8 = to_int8_dynamic(student_qatl_fp32)\n",
    "\n",
    "# Бейзлайны (FP32 + INT8 dynamic)\n",
    "baselines = build_baselines(num_classes)\n",
    "baselines_int8 = {}\n",
    "for name, m in baselines.items():\n",
    "    try:\n",
    "        baselines_int8[f'{name.replace(\"_fp32\",\"\")}_int8_ptq'] = to_int8_dynamic(m)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Метрики качества (val) для всех вариантов\n",
    "eval_targets: Dict[str, nn.Module] = {\n",
    "    'student_fp32': student_fp32,\n",
    "    'student_ema_fp32': student_ema_fp32,\n",
    "    'student_int8_ptq': student_int8,\n",
    "    'student_ema_int8_ptq': student_ema_int8,\n",
    "    'student_qatlite_fp32': student_qatl_fp32,\n",
    "    'student_qatlite_int8': student_qatl_int8,\n",
    "    **baselines,\n",
    "    **baselines_int8\n",
    "}\n",
    "\n",
    "metrics_summary = {}\n",
    "for tag, model in eval_targets.items():\n",
    "    lg, lb = collect_logits_labels(model, val_loader, device=torch.device('cpu'))\n",
    "    m = compute_metrics(lg, lb, [idx2label[i] for i in range(num_classes)])\n",
    "    metrics_summary[tag] = m\n",
    "    print(f'[VAL] {tag}: acc={m[\"accuracy\"]:.4f} macro-F1={m[\"macro_f1\"]:.4f} ROC-AUC={m[\"roc_auc_macro\"]:.4f}')\n",
    "\n",
    "# Финальный тест (один прогон, без аугм.)\n",
    "if test_loader is not None:\n",
    "    for tag in ['student_fp32', 'student_ema_fp32', 'student_int8_ptq', 'student_ema_int8_ptq',\n",
    "                'student_qatlite_fp32', 'student_qatlite_int8']:\n",
    "        if tag in eval_targets:\n",
    "            lg, lb = collect_logits_labels(eval_targets[tag], test_loader, device=torch.device('cpu'))\n",
    "            m = compute_metrics(lg, lb, [idx2label[i] for i in range(num_classes)])\n",
    "            metrics_summary[f'{tag}_TEST'] = m\n",
    "            print(f'[TEST] {tag}: acc={m[\"accuracy\"]:.4f} macro-F1={m[\"macro_f1\"]:.4f} ROC-AUC={m[\"roc_auc_macro\"]:.4f}')\n",
    "\n",
    "\n",
    "# CPU-бенчмарк (batch=1 и 8)\n",
    "cached_val_b1 = cache_batches(DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0), limit=64)\n",
    "cached_val_b8 = cache_batches(DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=0), limit=64)\n",
    "\n",
    "bench_rows = []\n",
    "for tag, model in eval_targets.items():\n",
    "    for bs, cached in [(1, cached_val_b1), (8, cached_val_b8)]:\n",
    "        res = benchmark_cpu(model, cached, warmup=50, measure=100, reps=5)\n",
    "        row = {'model': tag, 'batch': bs, **res}\n",
    "        bench_rows.append(row)\n",
    "        print(f'[CPU] {tag:24s} b={bs} | p50={res[\"p50_ms\"]:.2f}ms p90={res[\"p90_ms\"]:.2f}ms '\n",
    "              f'thr={res[\"thr_img_s\"]:.1f} img/s RAM={res[\"peak_ram_mb\"]:.1f}MB size={res[\"size_mb\"]:.2f}MB')\n",
    "\n",
    "# Params/FLOPs/Size\n",
    "desc_rows = []\n",
    "for tag, m in eval_targets.items():\n",
    "    try:\n",
    "        flops = count_flops(m, img_size=IMG_SIZE)\n",
    "    except Exception:\n",
    "        flops = None\n",
    "    params = count_params(m)\n",
    "    size_mb = state_dict_size_mb(m.state_dict()) if hasattr(m, 'state_dict') else float('nan')\n",
    "    desc_rows.append({'model': tag, 'params': int(params), 'flops': (int(flops) if flops else None), 'size_mb': float(size_mb)})\n"
   ],
   "id": "acc088132d2621b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train: loss=4.3309 acc=0.5741 | val: s=(0.7053,0.7431) ema=(1.4188,0.6122)\n",
      "Epoch 002 | train: loss=2.3092 acc=0.7229 | val: s=(0.5824,0.7855) ema=(0.8248,0.7556)\n",
      "Epoch 003 | train: loss=1.7262 acc=0.7721 | val: s=(1.1302,0.6833) ema=(0.6049,0.7893)\n",
      "Epoch 004 | train: loss=1.3769 acc=0.8090 | val: s=(0.5919,0.7693) ema=(0.5291,0.8030)\n",
      "Epoch 005 | train: loss=1.1160 acc=0.8356 | val: s=(0.7693,0.7207) ema=(0.4875,0.8155)\n",
      "Epoch 006 | train: loss=0.8964 acc=0.8571 | val: s=(0.4566,0.8242) ema=(0.4499,0.8304)\n",
      "Epoch 007 | train: loss=0.6969 acc=0.8798 | val: s=(0.4469,0.8192) ema=(0.4235,0.8392)\n",
      "Epoch 008 | train: loss=0.6293 acc=0.8877 | val: s=(0.4365,0.8441) ema=(0.4001,0.8441)\n",
      "Epoch 009 | train: loss=0.4860 acc=0.9090 | val: s=(0.3975,0.8416) ema=(0.3781,0.8541)\n",
      "Epoch 010 | train: loss=0.4292 acc=0.9164 | val: s=(0.3546,0.8579) ema=(0.3660,0.8566)\n",
      "Epoch 011 | train: loss=0.3748 acc=0.9264 | val: s=(0.3114,0.8803) ema=(0.3529,0.8641)\n",
      "Epoch 012 | train: loss=0.3392 acc=0.9335 | val: s=(0.3218,0.8803) ema=(0.3405,0.8628)\n",
      "Epoch 013 | train: loss=0.3195 acc=0.9403 | val: s=(0.3190,0.8766) ema=(0.3284,0.8716)\n",
      "Epoch 014 | train: loss=0.2955 acc=0.9436 | val: s=(0.2936,0.8878) ema=(0.3193,0.8766)\n",
      "Epoch 015 | train: loss=0.3040 acc=0.9407 | val: s=(0.2935,0.8853) ema=(0.3125,0.8791)\n",
      "Best val acc: student=0.8878 | ema=0.8791\n",
      "QAT-lite: epochs=5, lr=3e-05, wd=0.0, per_channel=True\n",
      "QAT 01/5 | train_loss=0.3390 | val_loss=0.3081 val_acc=0.8840\n",
      "QAT 02/5 | train_loss=0.3363 | val_loss=0.3070 val_acc=0.8865\n",
      "QAT 03/5 | train_loss=0.3198 | val_loss=0.2833 val_acc=0.8878\n",
      "QAT 04/5 | train_loss=0.3117 | val_loss=0.3008 val_acc=0.8828\n",
      "QAT 05/5 | train_loss=0.2950 | val_loss=0.3313 val_acc=0.8703\n",
      "[VAL] student_fp32: acc=0.8878 macro-F1=0.8874 ROC-AUC=0.9903\n",
      "[VAL] student_ema_fp32: acc=0.8791 macro-F1=0.8787 ROC-AUC=0.9889\n",
      "[VAL] student_int8_ptq: acc=0.8865 macro-F1=0.8901 ROC-AUC=0.9901\n",
      "[VAL] student_ema_int8_ptq: acc=0.8741 macro-F1=0.8700 ROC-AUC=0.9891\n",
      "[VAL] student_qatlite_fp32: acc=0.8678 macro-F1=0.8789 ROC-AUC=0.9908\n",
      "[VAL] student_qatlite_int8: acc=0.8666 macro-F1=0.8769 ROC-AUC=0.9907\n",
      "[VAL] resnet18_fp32: acc=0.0399 macro-F1=0.0251 ROC-AUC=0.4431\n",
      "[VAL] mobilenetv3_fp32: acc=0.0449 macro-F1=0.0440 ROC-AUC=0.5202\n",
      "[VAL] convnext_tiny_fp32: acc=0.1072 macro-F1=0.0532 ROC-AUC=0.5002\n",
      "[VAL] resnet18_int8_ptq: acc=0.0411 macro-F1=0.0256 ROC-AUC=0.4421\n",
      "[VAL] mobilenetv3_int8_ptq: acc=0.0449 macro-F1=0.0440 ROC-AUC=0.5202\n",
      "[VAL] convnext_tiny_int8_ptq: acc=0.1047 macro-F1=0.0494 ROC-AUC=0.5053\n",
      "[TEST] student_fp32: acc=0.8333 macro-F1=0.7857 ROC-AUC=0.9658\n",
      "[TEST] student_ema_fp32: acc=0.8367 macro-F1=0.7903 ROC-AUC=0.9657\n",
      "[TEST] student_int8_ptq: acc=0.8323 macro-F1=0.7865 ROC-AUC=0.9658\n",
      "[TEST] student_ema_int8_ptq: acc=0.8342 macro-F1=0.7908 ROC-AUC=0.9652\n",
      "[TEST] student_qatlite_fp32: acc=0.8103 macro-F1=0.7834 ROC-AUC=0.9634\n",
      "[TEST] student_qatlite_int8: acc=0.8113 macro-F1=0.7897 ROC-AUC=0.9631\n",
      "[CPU] student_fp32             b=1 | p50=14.53ms p90=15.91ms thr=67.7 img/s RAM=1765.1MB size=21.13MB\n",
      "[CPU] student_fp32             b=8 | p50=58.76ms p90=60.45ms thr=137.1 img/s RAM=1779.0MB size=21.13MB\n",
      "[CPU] student_ema_fp32         b=1 | p50=16.77ms p90=17.87ms thr=59.2 img/s RAM=1779.0MB size=21.13MB\n",
      "[CPU] student_ema_fp32         b=8 | p50=59.22ms p90=61.11ms thr=136.1 img/s RAM=1779.0MB size=21.13MB\n",
      "[CPU] student_int8_ptq         b=1 | p50=16.49ms p90=17.17ms thr=60.3 img/s RAM=1518.3MB size=5.97MB\n",
      "[CPU] student_int8_ptq         b=8 | p50=58.45ms p90=61.16ms thr=136.2 img/s RAM=1528.5MB size=5.97MB\n",
      "[CPU] student_ema_int8_ptq     b=1 | p50=14.46ms p90=16.84ms thr=66.9 img/s RAM=1532.2MB size=5.97MB\n",
      "[CPU] student_ema_int8_ptq     b=8 | p50=53.38ms p90=59.25ms thr=147.3 img/s RAM=1538.6MB size=5.97MB\n",
      "[CPU] student_qatlite_fp32     b=1 | p50=17.26ms p90=18.34ms thr=58.0 img/s RAM=1539.8MB size=21.13MB\n",
      "[CPU] student_qatlite_fp32     b=8 | p50=59.45ms p90=60.75ms thr=134.2 img/s RAM=1539.8MB size=21.13MB\n",
      "[CPU] student_qatlite_int8     b=1 | p50=15.77ms p90=17.55ms thr=62.3 img/s RAM=1533.2MB size=5.97MB\n",
      "[CPU] student_qatlite_int8     b=8 | p50=57.79ms p90=59.75ms thr=138.2 img/s RAM=1538.2MB size=5.97MB\n",
      "[CPU] resnet18_fp32            b=1 | p50=15.29ms p90=17.69ms thr=61.9 img/s RAM=1539.6MB size=42.72MB\n",
      "[CPU] resnet18_fp32            b=8 | p50=78.82ms p90=81.17ms thr=101.5 img/s RAM=1613.9MB size=42.72MB\n",
      "[CPU] mobilenetv3_fp32         b=1 | p50=16.58ms p90=17.19ms thr=60.4 img/s RAM=1616.1MB size=16.25MB\n",
      "[CPU] mobilenetv3_fp32         b=8 | p50=48.04ms p90=48.58ms thr=166.4 img/s RAM=1641.3MB size=16.25MB\n",
      "[CPU] convnext_tiny_fp32       b=1 | p50=38.28ms p90=39.21ms thr=26.4 img/s RAM=1642.2MB size=106.21MB\n",
      "[CPU] convnext_tiny_fp32       b=8 | p50=189.68ms p90=193.84ms thr=42.0 img/s RAM=1675.6MB size=106.21MB\n",
      "[CPU] resnet18_int8_ptq        b=1 | p50=17.54ms p90=19.04ms thr=56.3 img/s RAM=1675.7MB size=42.71MB\n",
      "[CPU] resnet18_int8_ptq        b=8 | p50=78.56ms p90=80.60ms thr=101.5 img/s RAM=1675.7MB size=42.71MB\n",
      "[CPU] mobilenetv3_int8_ptq     b=1 | p50=17.56ms p90=18.06ms thr=56.7 img/s RAM=1675.7MB size=16.25MB\n",
      "[CPU] mobilenetv3_int8_ptq     b=8 | p50=48.25ms p90=48.84ms thr=165.4 img/s RAM=1675.7MB size=16.25MB\n",
      "[CPU] convnext_tiny_int8_ptq   b=1 | p50=36.16ms p90=36.82ms thr=27.8 img/s RAM=1675.3MB size=32.18MB\n",
      "[CPU] convnext_tiny_int8_ptq   b=8 | p50=162.62ms p90=165.86ms thr=49.2 img/s RAM=1714.2MB size=32.18MB\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:08:32.616945Z",
     "start_time": "2025-08-19T21:08:31.274286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "@torch.no_grad()\n",
    "def export_torchscript(model: nn.Module, img_size=224, out_path='model_ts.pt'):\n",
    "    model = model.cpu().eval()\n",
    "    wrapped = ExportOnlyLogits(model)\n",
    "    dummy = torch.randn(1, 3, img_size, img_size, dtype=torch.float32)\n",
    "    ts = torch.jit.trace(wrapped, (dummy,), strict=False)\n",
    "    os.makedirs(os.path.dirname(out_path) or '.', exist_ok=True)\n",
    "    ts.save(out_path)\n",
    "    try:\n",
    "        loaded = torch.jit.load(out_path, map_location='cpu')\n",
    "        _ = loaded(dummy)\n",
    "        print('TorchScript verify: OK (forward)')\n",
    "    except Exception as e:\n",
    "        print(f'TorchScript verify: пропущен ({e})')\n",
    "    print(f'TorchScript -> {out_path}')\n",
    "\n",
    "# ======== Финальные вызовы экспорта (только TorchScript) ========\n",
    "export_dir = os.path.join(RESULTS_DIR, 'export')\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    if 'student_ema_int8' in globals():\n",
    "        export_torchscript(student_ema_int8, IMG_SIZE, os.path.join(export_dir, 'student_ema_int8_ts.pt'))\n",
    "    elif 'student_int8' in globals():\n",
    "        export_torchscript(student_int8, IMG_SIZE, os.path.join(export_dir, 'student_int8_ts.pt'))\n",
    "    elif 'student_qatl_int8' in globals():\n",
    "        export_torchscript(student_qatl_int8, IMG_SIZE, os.path.join(export_dir, 'student_qatl_int8_ts.pt'))\n",
    "    else:\n",
    "        print('Нет INT8‑модели в памяти для экспорта (ожидаются `student_ema_int8`/`student_int8`/`student_qatl_int8`).')\n",
    "except Exception as e:\n",
    "    print(f'Экспорт TorchScript пропущен: {e}')"
   ],
   "id": "2785e67a1b255016",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amirn\\PycharmProjects\\DS_builder\\.venv\\Lib\\site-packages\\torch\\__init__.py:2150: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchScript verify: OK (forward)\n",
      "TorchScript -> data\\results\\export\\student_ema_int8_ts.pt\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c63e62f85d990aa3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
