{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T15:39:49.611395Z",
     "start_time": "2025-08-19T15:39:49.570796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from EMA_for_weights import EMA\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms as T\n",
    "import timm\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# --- Repro/paths/hparams ---\n",
    "SEED = 42\n",
    "ISIC_ROOT = os.path.join('data', 'ISIC')\n",
    "TRAIN_CSV = os.path.join(ISIC_ROOT, 'split_train.csv')\n",
    "VAL_CSV = os.path.join(ISIC_ROOT, 'split_test.csv')\n",
    "LABELS_JSON = os.path.join(ISIC_ROOT, 'labels.json')\n",
    "\n",
    "CKPT_TEACHER = os.path.join('data', 'model_weights', 'deit_s_best.pth')\n",
    "CKPT_STUDENT = os.path.join('data', 'model_weights', 'student_best.pth')\n",
    "CKPT_STUDENT_EMA = CKPT_STUDENT.replace('.pth', '_ema.pth')\n",
    "os.makedirs(os.path.dirname(CKPT_STUDENT), exist_ok=True)\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "BASE_LR = 3e-4\n",
    "WEIGHT_DECAY = 0.05\n",
    "NUM_WORKERS = 0  # Windows/Jupyter\n",
    "KD_T = 4.0\n",
    "KD_ALPHA = 0.7\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "class ISICCsvDataset(Dataset):\n",
    "    def __init__(self, csv_path: str, label2idx=None, tfm=None):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'path' not in df.columns or 'label' not in df.columns:\n",
    "            raise ValueError(\"CSV должен содержать столбцы 'path' и 'label'\")\n",
    "        self.paths = df['path'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        if label2idx is None:\n",
    "            uniq = sorted(pd.unique(self.labels).tolist())\n",
    "            label2idx = {lbl: i for i, lbl in enumerate(uniq)}\n",
    "        self.label2idx = label2idx\n",
    "        self.tfm = tfm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.paths[idx]\n",
    "        y_str = self.labels[idx]\n",
    "        y = self.label2idx[y_str]\n",
    "        with Image.open(p) as img:\n",
    "            img = img.convert('RGB')\n",
    "        if self.tfm:\n",
    "            img = self.tfm(img)\n",
    "        return img, y\n",
    "\n",
    "def build_transforms(img_size=224):\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    train_tfm = T.Compose([\n",
    "        T.RandomResizedCrop(img_size, scale=(0.7, 1.0), ratio=(0.75, 1.33)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std),\n",
    "    ])\n",
    "    val_tfm = T.Compose([\n",
    "        T.Resize(int(img_size * 1.14)),\n",
    "        T.CenterCrop(img_size),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean, std),\n",
    "    ])\n",
    "    return train_tfm, val_tfm\n",
    "\n",
    "def make_weighted_sampler(labels_idx, num_classes):\n",
    "    counts = np.bincount(labels_idx, minlength=num_classes).astype(np.float32)\n",
    "    inv = 1.0 / np.maximum(counts, 1.0)\n",
    "    weights = [inv[y] for y in labels_idx]\n",
    "    return WeightedRandomSampler(weights, num_samples=len(weights), replacement=True), counts\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        total_correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return total_loss / max(total, 1), total_correct / max(total, 1)\n",
    "\n",
    "def kd_loss(student_logits, teacher_logits, labels, T=4.0, alpha=0.7):\n",
    "    soft = nn.KLDivLoss(reduction=\"batchmean\")(\n",
    "        F.log_softmax(student_logits / T, dim=1),\n",
    "        F.softmax(teacher_logits / T, dim=1)\n",
    "    ) * (T * T)\n",
    "    hard = F.cross_entropy(student_logits, labels)\n",
    "    return alpha * soft + (1 - alpha) * hard\n",
    "\n",
    "# --- Data/teacher/student/EMA ---\n",
    "set_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "with open(LABELS_JSON, 'r', encoding='utf-8') as f:\n",
    "    label2idx = json.load(f)\n",
    "idx2label = {v: k for k, v in label2idx.items()}\n",
    "num_classes = len(label2idx)\n",
    "\n",
    "train_tfm, val_tfm = build_transforms(IMG_SIZE)\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_labels_idx = [label2idx[l] for l in train_df['label'].tolist()]\n",
    "sampler, class_counts = make_weighted_sampler(train_labels_idx, num_classes)\n",
    "\n",
    "train_ds = ISICCsvDataset(TRAIN_CSV, label2idx=label2idx, tfm=train_tfm)\n",
    "val_ds = ISICCsvDataset(VAL_CSV, label2idx=label2idx, tfm=val_tfm)\n",
    "\n",
    "pin = device.type == 'cuda'\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=pin, persistent_workers=False)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=NUM_WORKERS, pin_memory=pin, persistent_workers=False)\n",
    "\n",
    "print('Распределение классов (train):', class_counts.tolist())"
   ],
   "id": "9b53f98b2fa377a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Распределение классов (train): [262.0, 411.0, 879.0, 92.0, 890.0, 5364.0, 114.0]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T16:06:56.612098Z",
     "start_time": "2025-08-19T15:39:50.917677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "teacher = timm.create_model('deit_small_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "ckpt_t = torch.load(CKPT_TEACHER, map_location='cpu')\n",
    "teacher.load_state_dict(ckpt_t['model'], strict=True)\n",
    "teacher.to(device).eval()\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "student = timm.create_model('deit_tiny_patch16_224', pretrained=True, num_classes=num_classes).to(device)\n",
    "ema = EMA(student, decay=0.999)\n",
    "\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(student.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))\n",
    "\n",
    "best_acc = 0.0\n",
    "best_acc_ema = 0.0\n",
    "\n",
    "# --- Train KD + EMA ---\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    student.train()\n",
    "    running_loss, running_correct, seen = 0.0, 0, 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{EPOCHS}', leave=False)\n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            t_logits = teacher(x)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast('cuda', enabled=(device.type == 'cuda')):\n",
    "            s_logits = student(x)\n",
    "            loss = kd_loss(s_logits, t_logits, y, T=KD_T, alpha=KD_ALPHA)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # EMA update\n",
    "        ema.update(student)\n",
    "\n",
    "        # stats\n",
    "        bs = y.size(0)\n",
    "        running_loss += loss.item() * bs\n",
    "        seen += bs\n",
    "        preds = s_logits.argmax(1)\n",
    "        running_correct += (preds == y).sum().item()\n",
    "        batch_acc = (preds == y).float().mean().item()\n",
    "\n",
    "        pbar.set_postfix(batch_loss=f'{loss.item():.4f}',\n",
    "                         batch_acc=f'{batch_acc:.4f}',\n",
    "                         lr=f\"{optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    train_loss = running_loss / max(seen, 1)\n",
    "    train_acc = running_correct / max(seen, 1)\n",
    "\n",
    "    val_loss, val_acc = evaluate(student, val_loader, device, criterion_ce)\n",
    "    val_loss_ema, val_acc_ema = evaluate(ema.ema_model, val_loader, device, criterion_ce)\n",
    "\n",
    "    print(f'Epoch {epoch:03d} | '\n",
    "          f'train_loss={train_loss:.4f}  train_acc={train_acc:.4f}  '\n",
    "          f'val_loss={val_loss:.4f}  val_acc={val_acc:.4f}  '\n",
    "          f'val_loss_ema={val_loss_ema:.4f}  val_acc_ema={val_acc_ema:.4f}  '\n",
    "          f'lr={scheduler.get_last_lr()[0]:.2e}')\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save({'model': student.state_dict(),\n",
    "                    'label2idx': label2idx,\n",
    "                    'epoch': epoch,\n",
    "                    'val_acc': val_acc}, CKPT_STUDENT)\n",
    "        print(f'Save best student -> {CKPT_STUDENT}')\n",
    "\n",
    "    if val_acc_ema > best_acc_ema:\n",
    "        best_acc_ema = val_acc_ema\n",
    "        torch.save({'model': ema.ema_model.state_dict(),\n",
    "                    'label2idx': label2idx,\n",
    "                    'epoch': epoch,\n",
    "                    'val_acc': val_acc_ema}, CKPT_STUDENT_EMA)\n",
    "        print(f'Save best student EMA -> {CKPT_STUDENT_EMA}')\n",
    "\n",
    "print(f'Best val_acc (student): {best_acc:.4f}')\n",
    "print(f'Best val_acc (student EMA): {best_acc_ema:.4f}')"
   ],
   "id": "dba1922290877474",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss=4.5493  train_acc=0.5549  val_loss=0.9843  val_acc=0.7144  val_loss_ema=1.6258  val_acc_ema=0.4413  lr=2.97e-04\n",
      "Save best student -> data\\model_weights\\student_best.pth\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 002 | train_loss=2.3536  train_acc=0.7159  val_loss=0.7749  val_acc=0.7424  val_loss_ema=1.0361  val_acc_ema=0.6540  lr=2.87e-04\n",
      "Save best student -> data\\model_weights\\student_best.pth\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 003 | train_loss=1.7870  train_acc=0.7681  val_loss=0.9308  val_acc=0.7054  val_loss_ema=0.7617  val_acc_ema=0.7189  lr=2.71e-04\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 004 | train_loss=1.3483  train_acc=0.8100  val_loss=1.0153  val_acc=0.7004  val_loss_ema=0.6464  val_acc_ema=0.7609  lr=2.50e-04\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 005 | train_loss=1.1082  train_acc=0.8298  val_loss=0.7065  val_acc=0.7818  val_loss_ema=0.6133  val_acc_ema=0.7718  lr=2.25e-04\n",
      "Save best student -> data\\model_weights\\student_best.pth\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 006 | train_loss=0.8252  train_acc=0.8676  val_loss=0.6541  val_acc=0.7868  val_loss_ema=0.5915  val_acc_ema=0.7863  lr=1.96e-04\n",
      "Save best student -> data\\model_weights\\student_best.pth\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 007 | train_loss=0.7681  train_acc=0.8702  val_loss=0.6470  val_acc=0.7888  val_loss_ema=0.5792  val_acc_ema=0.7948  lr=1.66e-04\n",
      "Save best student -> data\\model_weights\\student_best.pth\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 008 | train_loss=0.6103  train_acc=0.8895  val_loss=0.6202  val_acc=0.7973  val_loss_ema=0.5735  val_acc_ema=0.7978  lr=1.34e-04\n",
      "Save best student -> data\\model_weights\\student_best.pth\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 009 | train_loss=0.4925  train_acc=0.9033  val_loss=0.6828  val_acc=0.7773  val_loss_ema=0.5707  val_acc_ema=0.8033  lr=1.04e-04\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | train_loss=0.4323  train_acc=0.9177  val_loss=0.5504  val_acc=0.8273  val_loss_ema=0.5663  val_acc_ema=0.8078  lr=7.50e-05\n",
      "Save best student -> data\\model_weights\\student_best.pth\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 011 | train_loss=0.3914  train_acc=0.9230  val_loss=0.5468  val_acc=0.8233  val_loss_ema=0.5573  val_acc_ema=0.8138  lr=4.96e-05\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 012 | train_loss=0.3449  train_acc=0.9331  val_loss=0.5685  val_acc=0.8173  val_loss_ema=0.5507  val_acc_ema=0.8173  lr=2.86e-05\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 013 | train_loss=0.3279  train_acc=0.9392  val_loss=0.5678  val_acc=0.8228  val_loss_ema=0.5483  val_acc_ema=0.8223  lr=1.30e-05\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 014 | train_loss=0.3138  train_acc=0.9403  val_loss=0.5394  val_acc=0.8362  val_loss_ema=0.5462  val_acc_ema=0.8253  lr=3.28e-06\n",
      "Save best student -> data\\model_weights\\student_best.pth\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 015 | train_loss=0.3152  train_acc=0.9395  val_loss=0.5419  val_acc=0.8333  val_loss_ema=0.5445  val_acc_ema=0.8308  lr=0.00e+00\n",
      "Save best student EMA -> data\\model_weights\\student_best_ema.pth\n",
      "Best val_acc (student): 0.8362\n",
      "Best val_acc (student EMA): 0.8308\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Quantization (PTQ) and comparison",
   "id": "b359d3c4766b9611"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T16:06:58.019639Z",
     "start_time": "2025-08-19T16:06:58.012235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# python\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearWQAT(nn.Module):\n",
    "    def __init__(self, base_linear: nn.Linear, per_channel: bool = True):\n",
    "        super().__init__()\n",
    "        self.in_features = base_linear.in_features\n",
    "        self.out_features = base_linear.out_features\n",
    "        self.has_bias = base_linear.bias is not None\n",
    "\n",
    "        self.weight = nn.Parameter(base_linear.weight.detach().clone())\n",
    "        self.bias = nn.Parameter(base_linear.bias.detach().clone()) if self.has_bias else None\n",
    "\n",
    "        from torch.ao.quantization import FakeQuantize, default_per_channel_weight_observer, default_weight_observer\n",
    "        if per_channel:\n",
    "            self.weight_fake = FakeQuantize(\n",
    "                observer=default_per_channel_weight_observer,\n",
    "                quant_min=-128, quant_max=127,\n",
    "                dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0\n",
    "            )\n",
    "        else:\n",
    "            self.weight_fake = FakeQuantize(\n",
    "                observer=default_weight_observer,\n",
    "                quant_min=-128, quant_max=127,\n",
    "                dtype=torch.qint8, qscheme=torch.per_tensor_symmetric\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        w_q = self.weight_fake(self.weight)\n",
    "        return F.linear(x, w_q, self.bias)"
   ],
   "id": "21f9bdf08058ef8b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T16:08:25.740988Z",
     "start_time": "2025-08-19T16:06:59.380233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import io\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm\n",
    "\n",
    "torch.backends.quantized.engine = 'fbgemm'  # Windows/x86\n",
    "\n",
    "CKPT_STUDENT = os.path.join('data', 'model_weights', 'student_best.pth')\n",
    "CKPT_STUDENT_INT8 = CKPT_STUDENT.replace('.pth', '_int8.pth')\n",
    "CKPT_STUDENT_EMA = CKPT_STUDENT.replace('.pth', '_ema.pth')\n",
    "CKPT_STUDENT_EMA_INT8 = CKPT_STUDENT_EMA.replace('.pth', '_int8.pth')\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_logits(model, loader, device):\n",
    "    model.eval().to(device)\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    all_logits, all_labels = [], []\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = ce(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        correct += (logits.argmax(1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(y.cpu())\n",
    "    return torch.cat(all_logits, 0), torch.cat(all_labels, 0), total_loss / max(total, 1), correct / max(total, 1)\n",
    "\n",
    "def state_dict_size_bytes(state_dict):\n",
    "    buf = io.BytesIO()\n",
    "    torch.save(state_dict, buf)\n",
    "    return buf.tell()\n",
    "\n",
    "# 1) Load FP32 student and EMA-student\n",
    "student_fp32 = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "ckpt_s = torch.load(CKPT_STUDENT, map_location='cpu')\n",
    "student_fp32.load_state_dict(ckpt_s['model'], strict=True)\n",
    "\n",
    "student_ema_fp32 = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "ckpt_se = torch.load(CKPT_STUDENT_EMA, map_location='cpu')\n",
    "student_ema_fp32.load_state_dict(ckpt_se['model'], strict=True)\n",
    "\n",
    "# 2) Evaluate FP32 on CPU\n",
    "logits_s_fp32, labels_cpu, s_fp32_loss, s_fp32_acc = eval_logits(student_fp32, val_loader, device=torch.device('cpu'))\n",
    "logits_se_fp32, _, se_fp32_loss, se_fp32_acc = eval_logits(student_ema_fp32, val_loader, device=torch.device('cpu'))\n",
    "\n",
    "# 3) Dynamic INT8 quantization and eval\n",
    "student_int8 = torch.ao.quantization.quantize_dynamic(copy.deepcopy(student_fp32), {nn.Linear}, dtype=torch.qint8)\n",
    "student_ema_int8 = torch.ao.quantization.quantize_dynamic(copy.deepcopy(student_ema_fp32), {nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "logits_s_int8, _, s_int8_loss, s_int8_acc = eval_logits(student_int8, val_loader, device=torch.device('cpu'))\n",
    "logits_se_int8, _, se_int8_loss, se_int8_acc = eval_logits(student_ema_int8, val_loader, device=torch.device('cpu'))\n",
    "\n",
    "# 4) Outputs and sizes comparison\n",
    "with torch.no_grad():\n",
    "    mae_s = (logits_s_fp32 - logits_s_int8.float()).abs().mean().item()\n",
    "    top1_s = (logits_s_fp32.argmax(1) == logits_s_int8.argmax(1)).float().mean().item()\n",
    "    kl_s = F.kl_div(F.log_softmax(logits_s_int8.float(), dim=1), F.softmax(logits_s_fp32, dim=1), reduction='batchmean').item()\n",
    "\n",
    "    mae_se = (logits_se_fp32 - logits_se_int8.float()).abs().mean().item()\n",
    "    top1_se = (logits_se_fp32.argmax(1) == logits_se_int8.argmax(1)).float().mean().item()\n",
    "    kl_se = F.kl_div(F.log_softmax(logits_se_int8.float(), dim=1), F.softmax(logits_se_fp32, dim=1), reduction='batchmean').item()\n",
    "\n",
    "sd_s_fp32 = student_fp32.state_dict()\n",
    "sd_s_int8 = student_int8.state_dict()\n",
    "sd_se_fp32 = student_ema_fp32.state_dict()\n",
    "sd_se_int8 = student_ema_int8.state_dict()\n",
    "\n",
    "size_s_fp32 = state_dict_size_bytes(sd_s_fp32)\n",
    "size_s_int8 = state_dict_size_bytes(sd_s_int8)\n",
    "size_se_fp32 = state_dict_size_bytes(sd_se_fp32)\n",
    "size_se_int8 = state_dict_size_bytes(sd_se_int8)\n",
    "\n",
    "# 5) Save INT8 checkpoints\n",
    "torch.save({'model': sd_s_int8, 'label2idx': label2idx, 'from': CKPT_STUDENT}, CKPT_STUDENT_INT8)\n",
    "torch.save({'model': sd_se_int8, 'label2idx': label2idx, 'from': CKPT_STUDENT_EMA}, CKPT_STUDENT_EMA_INT8)\n",
    "\n",
    "# 6) Print\n",
    "print('=== Сравнение FP32 vs INT8 (CPU) — Student ===')\n",
    "print(f'val_acc FP32: {s_fp32_acc:.4f} | INT8: {s_int8_acc:.4f} | Δ: {s_int8_acc - s_fp32_acc:+.4f}')\n",
    "print(f'val_loss FP32: {s_fp32_loss:.4f} | INT8: {s_int8_loss:.4f} | Δ: {s_int8_loss - s_fp32_loss:+.4f}')\n",
    "print(f'Top-1 совпадение: {top1_s:.4f} | MAE logits: {mae_s:.6f} | KL(fp32||int8): {kl_s:.6f}')\n",
    "print(f'Размер FP32: {size_s_fp32/1024/1024:.2f} MB | INT8: {size_s_int8/1024/1024:.2f} MB '\n",
    "      f'({(size_s_int8/size_s_fp32)*100:.1f}% от FP32)')\n",
    "print(f'INT8 сохранён: {CKPT_STUDENT_INT8}')\n",
    "\n",
    "print('\\n=== Сравнение FP32 vs INT8 (CPU) — Student EMA ===')\n",
    "print(f'val_acc FP32: {se_fp32_acc:.4f} | INT8: {se_int8_acc:.4f} | Δ: {se_int8_acc - se_fp32_acc:+.4f}')\n",
    "print(f'val_loss FP32: {se_fp32_loss:.4f} | INT8: {se_int8_loss:.4f} | Δ: {se_int8_loss - se_fp32_loss:+.4f}')\n",
    "print(f'Top-1 совпадение: {top1_se:.4f} | MAE logits: {mae_se:.6f} | KL(fp32||int8): {kl_se:.6f}')\n",
    "print(f'Размер FP32: {size_se_fp32/1024/1024:.2f} MB | INT8: {size_se_int8/1024/1024:.2f} MB '\n",
    "      f'({(size_se_int8/size_se_fp32)*100:.1f}% от FP32)')\n",
    "print(f'INT8 сохранён: {CKPT_STUDENT_EMA_INT8}')"
   ],
   "id": "6c2b8c6a2871391b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Сравнение FP32 vs INT8 (CPU) — Student ===\n",
      "val_acc FP32: 0.8362 | INT8: 0.8337 | Δ: -0.0025\n",
      "val_loss FP32: 0.5394 | INT8: 0.5437 | Δ: +0.0043\n",
      "Top-1 совпадение: 0.9870 | MAE logits: 0.065218 | KL(fp32||int8): 0.001641\n",
      "Размер FP32: 21.13 MB | INT8: 5.97 MB (28.3% от FP32)\n",
      "INT8 сохранён: data\\model_weights\\student_best_int8.pth\n",
      "\n",
      "=== Сравнение FP32 vs INT8 (CPU) — Student EMA ===\n",
      "val_acc FP32: 0.8308 | INT8: 0.8288 | Δ: -0.0020\n",
      "val_loss FP32: 0.5445 | INT8: 0.5456 | Δ: +0.0011\n",
      "Top-1 совпадение: 0.9870 | MAE logits: 0.065542 | KL(fp32||int8): 0.002174\n",
      "Размер FP32: 21.13 MB | INT8: 5.97 MB (28.3% от FP32)\n",
      "INT8 сохранён: data\\model_weights\\student_best_ema_int8.pth\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## QAT-lite (fake-quant weights of nn.Linear) and PTQ vs QAT-lite comparison",
   "id": "caec7a72f606b2db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T16:17:23.969416Z",
     "start_time": "2025-08-19T16:08:32.832404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "# Пути для QAT-lite\n",
    "CKPT_STUDENT_QAT = CKPT_STUDENT.replace('.pth', '_qatlite.pth')\n",
    "CKPT_STUDENT_QAT_INT8 = CKPT_STUDENT_QAT.replace('.pth', '_int8.pth')\n",
    "\n",
    "# Гиперпараметры QAT-lite\n",
    "QAT_EPOCHS = 5  # 3–10\n",
    "QAT_LR = 3e-5  # малый LR\n",
    "QAT_WD = 0.0\n",
    "QAT_PER_CHANNEL = True  # per-channel fake-quant\n",
    "\n",
    "\n",
    "def wrap_linears_with_wqat(module: nn.Module, per_channel=True):\n",
    "    for name, child in list(module.named_children()):\n",
    "        if isinstance(child, nn.Linear):\n",
    "            setattr(module, name, LinearWQAT(child, per_channel=per_channel))\n",
    "        else:\n",
    "            wrap_linears_with_wqat(child, per_channel=per_channel)\n",
    "    return module\n",
    "\n",
    "\n",
    "def unwrap_wqat_to_linear(module: nn.Module):\n",
    "    for name, child in list(module.named_children()):\n",
    "        if isinstance(child, LinearWQAT):\n",
    "            lin = nn.Linear(child.in_features, child.out_features, bias=child.has_bias)\n",
    "            with torch.no_grad():\n",
    "                lin.weight.copy_(child.weight.data)\n",
    "                if child.has_bias:\n",
    "                    lin.bias.copy_(child.bias.data)\n",
    "            setattr(module, name, lin)\n",
    "        else:\n",
    "            unwrap_wqat_to_linear(child)\n",
    "    return module\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_acc_loss(model, loader, device):\n",
    "    model.eval().to(device)\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        loss = ce(logits, y)\n",
    "        total_loss += loss.item() * y.size(0)\n",
    "        correct += (logits.argmax(1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    return total_loss / max(total, 1), correct / max(total, 1)\n",
    "\n",
    "\n",
    "# 0) База для QAT-lite: берём EMA-студента если есть\n",
    "student_base = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "if os.path.isfile(CKPT_STUDENT_EMA):\n",
    "    ckpt_base = torch.load(CKPT_STUDENT_EMA, map_path='cpu')\n",
    "else:\n",
    "    ckpt_base = torch.load(CKPT_STUDENT, map_path='cpu')  # fallback\n",
    "    if 'model' not in ckpt_base:\n",
    "        ckpt_base = torch.load(CKPT_STUDENT, map_location='cpu')\n",
    "student_base.load_state_dict(ckpt_base['model'], strict=True)\n",
    "\n",
    "# Базовая PTQ (динамическая) для сравнения\n",
    "ptq_base = torch.ao.quantization.quantize_dynamic(copy.deepcopy(student_base), {nn.Linear}, dtype=torch.qint8)\n",
    "ptq_loss, ptq_acc = eval_acc_loss(ptq_base, val_loader, device=torch.device('cpu'))\n",
    "\n",
    "# 1) Готовим и обучаем QAT-lite\n",
    "student_qat = copy.deepcopy(student_base)\n",
    "student_qat = wrap_linears_with_wqat(student_qat, per_channel=QAT_PER_CHANNEL)\n",
    "student_qat.to(device)\n",
    "\n",
    "teacher.eval().to(device)\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "optimizer_qat = torch.optim.AdamW(student_qat.parameters(), lr=QAT_LR, weight_decay=QAT_WD)\n",
    "\n",
    "print(f'QAT-lite start: epochs={QAT_EPOCHS}, lr={QAT_LR}, wd={QAT_WD}')\n",
    "for epoch in range(1, QAT_EPOCHS + 1):\n",
    "    student_qat.train()\n",
    "    run_loss, seen = 0.0, 0\n",
    "    for x, y in tqdm(train_loader, desc=f'QAT-lite {epoch}/{QAT_EPOCHS}', leave=False):\n",
    "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            t_logits = teacher(x)\n",
    "        optimizer_qat.zero_grad(set_to_none=True)\n",
    "        # без AMP для стабильности fake-quant\n",
    "        s_logits = student_qat(x)\n",
    "        loss = kd_loss(s_logits, t_logits, y, T=KD_T, alpha=KD_ALPHA)\n",
    "        loss.backward()\n",
    "        optimizer_qat.step()\n",
    "\n",
    "        bs = y.size(0)\n",
    "        run_loss += loss.item() * bs\n",
    "        seen += bs\n",
    "    val_loss_qat, val_acc_qat = eval_acc_loss(student_qat, val_loader, device)\n",
    "    print(\n",
    "        f'Epoch {epoch:02d} | train_loss={run_loss / max(seen, 1):.4f}  val_loss={val_loss_qat:.4f}  val_acc={val_acc_qat:.4f}')\n",
    "\n",
    "# 2) Разворачиваем в Linear и сохраняем FP32 чекпойнт\n",
    "student_qat_fp32 = copy.deepcopy(student_qat).cpu()\n",
    "student_qat_fp32 = unwrap_wqat_to_linear(student_qat_fp32)\n",
    "torch.save({'model': student_qat_fp32.state_dict(), 'label2idx': label2idx}, CKPT_STUDENT_QAT)\n",
    "print(f'Save QAT-lite FP32 -> {CKPT_STUDENT_QAT}')\n",
    "\n",
    "# 3) INT8 после QAT-lite и оценка\n",
    "student_qat_int8 = torch.ao.quantization.quantize_dynamic(copy.deepcopy(student_qat_fp32), {nn.Linear},\n",
    "                                                          dtype=torch.qint8)\n",
    "qat_int8_loss, qat_int8_acc = eval_acc_loss(student_qat_int8, val_loader, device=torch.device('cpu'))\n",
    "torch.save({'model': student_qat_int8.state_dict(), 'label2idx': label2idx, 'from': CKPT_STUDENT_QAT},\n",
    "           CKPT_STUDENT_QAT_INT8)\n",
    "print(f'Save QAT-lite INT8 -> {CKPT_STUDENT_QAT_INT8}')\n",
    "\n",
    "# 4) Финальное сравнение INT8: PTQ(EMA) vs QAT-lite(EMA)\n",
    "print('\\n=== CPU INT8: PTQ(EMA) vs QAT-lite(EMA) ===')\n",
    "print(f'PTQ  INT8 -> val_loss: {ptq_loss:.4f}  val_acc: {ptq_acc:.4f}')\n",
    "print(f'QATL INT8 -> val_loss: {qat_int8_loss:.4f}  val_acc: {qat_int8_acc:.4f}')\n",
    "print(f'Δacc (QAT-lite - PTQ): {qat_int8_acc - ptq_acc:+.4f}')"
   ],
   "id": "eec183a01bee792c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAT-lite start: epochs=5, lr=3e-05, wd=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.3321  val_loss=0.5259  val_acc=0.8342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=0.3282  val_loss=0.5572  val_acc=0.8208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=0.3249  val_loss=0.5293  val_acc=0.8342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=0.3198  val_loss=0.5771  val_acc=0.8138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=0.3078  val_loss=0.5415  val_acc=0.8253\n",
      "Save QAT-lite FP32 -> data\\model_weights\\student_best_qatlite.pth\n",
      "Save QAT-lite INT8 -> data\\model_weights\\student_best_qatlite_int8.pth\n",
      "\n",
      "=== CPU INT8: PTQ(EMA) vs QAT-lite(EMA) ===\n",
      "PTQ  INT8 -> val_loss: 0.5456  val_acc: 0.8288\n",
      "QATL INT8 -> val_loss: 0.5446  val_acc: 0.8238\n",
      "Δacc (QAT-lite - PTQ): -0.0050\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  CPU-бенчмарк",
   "id": "97133dce021b3a1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T16:37:20.505633Z",
     "start_time": "2025-08-19T16:37:20.355050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# python\n",
    "# =========================\n",
    "# Блок 1. CPU-бенчмарк\n",
    "# =========================\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import psutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "torch.backends.quantized.engine = 'fbgemm'  # x86/Windows\n",
    "\n",
    "def cache_batches(loader, limit=None):\n",
    "    \"\"\"Загружает несколько батчей в RAM для стабильных замеров (исключая I/O/аугментации во время замеров).\"\"\"\n",
    "    cached = []\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        cached.append((x.cpu(), y.cpu()))\n",
    "        if limit is not None and (i + 1) >= limit:\n",
    "            break\n",
    "    return cached\n",
    "\n",
    "@torch.no_grad()\n",
    "def benchmark_cpu(model: torch.nn.Module,\n",
    "                  cached_batches,\n",
    "                  warmup_steps=50,\n",
    "                  measure_steps=100,\n",
    "                  reps=5):\n",
    "    \"\"\"Возвращает словарь: p50/p90 latency (мс), throughput (img/s), peak_ram_mb.\"\"\"\n",
    "    proc = psutil.Process(os.getpid())\n",
    "    model.eval().to('cpu')\n",
    "    lat_ms = []\n",
    "    total_imgs = 0\n",
    "    total_time = 0.0\n",
    "    peak_rss = proc.memory_info().rss\n",
    "\n",
    "    # Фиксируем список батчей для циклического прохода\n",
    "    if not cached_batches:\n",
    "        raise RuntimeError('Нет закешированных батчей для бенчмарка.')\n",
    "    nb = len(cached_batches)\n",
    "\n",
    "    # Прогрев\n",
    "    j = 0\n",
    "    for _ in range(warmup_steps):\n",
    "        x, _ = cached_batches[j % nb]\n",
    "        j += 1\n",
    "        _ = model(x)  # forward на CPU\n",
    "        peak_rss = max(peak_rss, proc.memory_info().rss)\n",
    "\n",
    "    # Замеры\n",
    "    j = 0\n",
    "    for _ in range(reps):\n",
    "        run_imgs = 0\n",
    "        run_time = 0.0\n",
    "        for _ in range(measure_steps):\n",
    "            x, _ = cached_batches[j % nb]\n",
    "            j += 1\n",
    "            t0 = time.perf_counter()\n",
    "            _ = model(x)\n",
    "            dt = time.perf_counter() - t0\n",
    "            lat_ms.append(dt * 1e3)\n",
    "            run_imgs += x.size(0)\n",
    "            run_time += dt\n",
    "            peak_rss = max(peak_rss, proc.memory_info().rss)\n",
    "        total_imgs += run_imgs\n",
    "        total_time += run_time\n",
    "\n",
    "    lat_ms = np.asarray(lat_ms, dtype=np.float64)\n",
    "    p50 = float(np.percentile(lat_ms, 50))\n",
    "    p90 = float(np.percentile(lat_ms, 90))\n",
    "    thr = float(total_imgs / total_time) if total_time > 0 else float('nan')\n",
    "    peak_mb = peak_rss / (1024.0 * 1024.0)\n",
    "    return {'latency_p50_ms': p50, 'latency_p90_ms': p90, 'throughput_img_s': thr, 'peak_ram_mb': peak_mb}\n",
    "\n",
    "def build_student_fp32(num_classes: int, ckpt_path: str):\n",
    "    m = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "    sd = torch.load(ckpt_path, map_location='cpu')['model']\n",
    "    m.load_state_dict(sd, strict=True)\n",
    "    return m\n",
    "\n",
    "def build_student_ema_fp32(num_classes: int, ckpt_path: str):\n",
    "    m = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "    sd = torch.load(ckpt_path, map_location='cpu')['model']\n",
    "    m.load_state_dict(sd, strict=True)\n",
    "    return m\n",
    "\n",
    "def to_int8_dynamic(fp32_model: nn.Module):\n",
    "    return torch.ao.quantization.quantize_dynamic(fp32_model, {nn.Linear}, dtype=torch.qint8)\n",
    "\n",
    "# Подхватим уже определённые объекты и пути (есть в ноутбуке выше),\n",
    "# а при их отсутствии — создадим/определим.\n",
    "try:\n",
    "    num_classes\n",
    "except NameError:\n",
    "    # На всякий случай — читаем labels.json\n",
    "    import json\n",
    "    with open(os.path.join('data', 'ISIC', 'labels.json'), 'r', encoding='utf-8') as f:\n",
    "        label2idx = json.load(f)\n",
    "    num_classes = len(label2idx)\n",
    "\n",
    "CKPT_STUDENT = os.path.join('data', 'model_weights', 'student_best.pth')\n",
    "CKPT_STUDENT_EMA = CKPT_STUDENT.replace('.pth', '_ema.pth')\n",
    "CKPT_STUDENT_QAT = CKPT_STUDENT.replace('.pth', '_qatlite.pth')\n",
    "\n",
    "# Собираем модели для сравнения\n",
    "models_for_bench = {}\n",
    "\n",
    "# FP32 student\n",
    "try:\n",
    "    models_for_bench['student_fp32'] = student_fp32  # из предыдущего блока, если есть\n",
    "except NameError:\n",
    "    if os.path.isfile(CKPT_STUDENT):\n",
    "        models_for_bench['student_fp32'] = build_student_fp32(num_classes, CKPT_STUDENT)\n",
    "\n",
    "# FP32 student EMA\n",
    "try:\n",
    "    models_for_bench['student_ema_fp32'] = student_ema_fp32\n",
    "except NameError:\n",
    "    if os.path.isfile(CKPT_STUDENT_EMA):\n",
    "        models_for_bench['student_ema_fp32'] = build_student_ema_fp32(num_classes, CKPT_STUDENT_EMA)\n",
    "\n",
    "# INT8 (PTQ) — строим на лету из FP32\n",
    "if 'student_fp32' in models_for_bench:\n",
    "    models_for_bench['student_int8_ptq'] = to_int8_dynamic(timm.create_model(\n",
    "        'deit_tiny_patch16_224', pretrained=False, num_classes=num_classes\n",
    "    ).load_state_dict(models_for_bench['student_fp32'].state_dict()) or models_for_bench['student_fp32'])\n",
    "\n",
    "if 'student_ema_fp32' in models_for_bench:\n",
    "    models_for_bench['student_ema_int8_ptq'] = to_int8_dynamic(timm.create_model(\n",
    "        'deit_tiny_patch16_224', pretrained=False, num_classes=num_classes\n",
    "    ).load_state_dict(models_for_bench['student_ema_fp32'].state_dict()) or models_for_bench['student_ema_fp32'])\n",
    "\n",
    "# QAT-lite FP32 (если есть чекпойнт) + его INT8\n",
    "if os.path.isfile(CKPT_STUDENT_QAT):\n",
    "    m_qat = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "    m_qat.load_state_dict(torch.load(CKPT_STUDENT_QAT, map_location='cpu')['model'], strict=True)\n",
    "    models_for_bench['student_qatlite_fp32'] = m_qat\n",
    "    models_for_bench['student_qatlite_int8'] = to_int8_dynamic(copy.deepcopy(m_qat))\n",
    "\n",
    "# Готовим батчи для стабильных замеров (например, 64 батча из val_loader)\n",
    "try:\n",
    "    val_loader\n",
    "except NameError:\n",
    "    raise RuntimeError('val_loader не найден. Выполните блок подготовки данных выше.')\n",
    "cached_val = cache_batches(val_loader, limit=64)\n",
    "\n",
    "print('=== CPU benchmark (batch из val_loader) ===')\n",
    "for name, model in models_for_bench.items():\n",
    "    m = model  # уже собран\n",
    "    res = benchmark_cpu(m, cached_val, warmup_steps=50, measure_steps=100, reps=5)\n",
    "    print(f'{name:>22s} | p50={res[\"latency_p50_ms\"]:.2f} ms | p90={res[\"latency_p90_ms\"]:.2f} ms | '\n",
    "          f'thr={res[\"throughput_img_s\"]:.1f} img/s | peak RAM={res[\"peak_ram_mb\"]:.1f} MB')\n"
   ],
   "id": "e4d24a3468e3a9c0",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_IncompatibleKeys' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 126\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;66;03m# INT8 (PTQ) — строим на лету из FP32\u001B[39;00m\n\u001B[32m    125\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mstudent_fp32\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m models_for_bench:\n\u001B[32m--> \u001B[39m\u001B[32m126\u001B[39m     models_for_bench[\u001B[33m'\u001B[39m\u001B[33mstudent_int8_ptq\u001B[39m\u001B[33m'\u001B[39m] = \u001B[43mto_int8_dynamic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimm\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcreate_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdeit_tiny_patch16_224\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpretrained\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_classes\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodels_for_bench\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mstudent_fp32\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstate_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmodels_for_bench\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mstudent_fp32\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m'\u001B[39m\u001B[33mstudent_ema_fp32\u001B[39m\u001B[33m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m models_for_bench:\n\u001B[32m    131\u001B[39m     models_for_bench[\u001B[33m'\u001B[39m\u001B[33mstudent_ema_int8_ptq\u001B[39m\u001B[33m'\u001B[39m] = to_int8_dynamic(timm.create_model(\n\u001B[32m    132\u001B[39m         \u001B[33m'\u001B[39m\u001B[33mdeit_tiny_patch16_224\u001B[39m\u001B[33m'\u001B[39m, pretrained=\u001B[38;5;28;01mFalse\u001B[39;00m, num_classes=num_classes\n\u001B[32m    133\u001B[39m     ).load_state_dict(models_for_bench[\u001B[33m'\u001B[39m\u001B[33mstudent_ema_fp32\u001B[39m\u001B[33m'\u001B[39m].state_dict()) \u001B[38;5;129;01mor\u001B[39;00m models_for_bench[\u001B[33m'\u001B[39m\u001B[33mstudent_ema_fp32\u001B[39m\u001B[33m'\u001B[39m])\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 90\u001B[39m, in \u001B[36mto_int8_dynamic\u001B[39m\u001B[34m(fp32_model)\u001B[39m\n\u001B[32m     89\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mto_int8_dynamic\u001B[39m(fp32_model: nn.Module):\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mao\u001B[49m\u001B[43m.\u001B[49m\u001B[43mquantization\u001B[49m\u001B[43m.\u001B[49m\u001B[43mquantize_dynamic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp32_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mLinear\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mqint8\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DS_builder\\.venv\\Lib\\site-packages\\torch\\ao\\quantization\\quantize.py:558\u001B[39m, in \u001B[36mquantize_dynamic\u001B[39m\u001B[34m(model, qconfig_spec, dtype, mapping, inplace)\u001B[39m\n\u001B[32m    556\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m inplace:\n\u001B[32m    557\u001B[39m     model = copy.deepcopy(model)\n\u001B[32m--> \u001B[39m\u001B[32m558\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43meval\u001B[49m()\n\u001B[32m    559\u001B[39m propagate_qconfig_(model, qconfig_spec)\n\u001B[32m    560\u001B[39m convert(model, mapping, inplace=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mAttributeError\u001B[39m: '_IncompatibleKeys' object has no attribute 'eval'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Метрики качества",
   "id": "b2ff16d11987d81b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =========================\n",
    "# Блок 2. Метрики качества\n",
    "# =========================\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_logits_labels(model: nn.Module, loader, device=torch.device('cpu')):\n",
    "    model.eval().to(device)\n",
    "    logits_list, labels_list = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        logits_list.append(logits.cpu())\n",
    "        labels_list.append(y.cpu())\n",
    "    logits = torch.cat(logits_list, dim=0)\n",
    "    labels = torch.cat(labels_list, dim=0)\n",
    "    return logits, labels\n",
    "\n",
    "def compute_classification_metrics(logits: torch.Tensor,\n",
    "                                   labels: torch.Tensor,\n",
    "                                   class_names=None):\n",
    "    y_true = labels.numpy()\n",
    "    y_pred = logits.argmax(dim=1).numpy()\n",
    "    num_classes = logits.size(1)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    # per-class precision/recall/f1/support\n",
    "    prec_c, rec_c, f1_c, supp_c = precision_recall_fscore_support(\n",
    "        y_true, y_pred, labels=np.arange(num_classes), average=None, zero_division=0\n",
    "    )\n",
    "\n",
    "    # ROC-AUC (macro)\n",
    "    y_prob = F.softmax(logits, dim=1).numpy()\n",
    "    try:\n",
    "        if num_classes == 2:\n",
    "            roc_auc_macro = roc_auc_score(y_true, y_prob[:, 1])\n",
    "        else:\n",
    "            roc_auc_macro = roc_auc_score(y_true, y_prob, multi_class='ovr', average='macro')\n",
    "    except ValueError:\n",
    "        roc_auc_macro = float('nan')  # если в y_true отсутствует какой-то класс\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))\n",
    "\n",
    "    per_class = []\n",
    "    for i in range(num_classes):\n",
    "        name = class_names[i] if (class_names is not None and i < len(class_names)) else f'class_{i}'\n",
    "        per_class.append({\n",
    "            'class': name,\n",
    "            'precision': float(prec_c[i]),\n",
    "            'recall': float(rec_c[i]),\n",
    "            'f1': float(f1_c[i]),\n",
    "            'support': int(supp_c[i]),\n",
    "        })\n",
    "\n",
    "    return {\n",
    "        'accuracy': float(acc),\n",
    "        'macro_f1': float(macro_f1),\n",
    "        'roc_auc_macro': float(roc_auc_macro) if not math.isnan(roc_auc_macro) else float('nan'),\n",
    "        'per_class': per_class,\n",
    "        'confusion_matrix': cm.astype(int).tolist(),\n",
    "    }\n",
    "\n",
    "def print_metrics(tag: str, m: dict, max_classes=20):\n",
    "    print(f'[{tag}] accuracy={m[\"accuracy\"]:.4f} | macro-F1={m[\"macro_f1\"]:.4f} | ROC-AUC(macro)={m[\"roc_auc_macro\"]:.4f}')\n",
    "    print('per-class (precision/recall/f1/support):')\n",
    "    for i, row in enumerate(m['per_class'][:max_classes]):\n",
    "        print(f'  {row[\"class\"]:<16s} P={row[\"precision\"]:.3f} R={row[\"recall\"]:.3f} F1={row[\"f1\"]:.3f} n={row[\"support\"]}')\n",
    "    if len(m['per_class']) > max_classes:\n",
    "        print(f'  ... {len(m[\"per_class\"]) - max_classes} классов скрыто')\n",
    "    cm = np.array(m['confusion_matrix'], dtype=int)\n",
    "    print(f'confusion matrix: shape={cm.shape}, sum={cm.sum()}')\n",
    "\n",
    "# Имена классов (если есть)\n",
    "try:\n",
    "    idx2label\n",
    "except NameError:\n",
    "    try:\n",
    "        with open(os.path.join('data', 'ISIC', 'labels.json'), 'r', encoding='utf-8') as f:\n",
    "            label2idx = json.load(f)\n",
    "        idx2label = {v: k for k, v in label2idx.items()}\n",
    "    except Exception:\n",
    "        idx2label = None\n",
    "class_names = [idx2label[i] for i in range(len(idx2label))] if idx2label else None\n",
    "\n",
    "# Примеры расчёта метрик на CPU для FP32/INT8\n",
    "metrics_targets = {}\n",
    "if 'student_fp32' in models_for_bench:\n",
    "    lg, lb = collect_logits_labels(models_for_bench['student_fp32'], val_loader, device=torch.device('cpu'))\n",
    "    metrics_targets['student_fp32'] = compute_classification_metrics(lg, lb, class_names)\n",
    "\n",
    "if 'student_int8_ptq' in models_for_bench:\n",
    "    lg, lb = collect_logits_labels(models_for_bench['student_int8_ptq'], val_loader, device=torch.device('cpu'))\n",
    "    metrics_targets['student_int8_ptq'] = compute_classification_metrics(lg, lb, class_names)\n",
    "\n",
    "if 'student_ema_fp32' in models_for_bench:\n",
    "    lg, lb = collect_logits_labels(models_for_bench['student_ema_fp32'], val_loader, device=torch.device('cpu'))\n",
    "    metrics_targets['student_ema_fp32'] = compute_classification_metrics(lg, lb, class_names)\n",
    "\n",
    "if 'student_ema_int8_ptq' in models_for_bench:\n",
    "    lg, lb = collect_logits_labels(models_for_bench['student_ema_int8_ptq'], val_loader, device=torch.device('cpu'))\n",
    "    metrics_targets['student_ema_int8_ptq'] = compute_classification_metrics(lg, lb, class_names)\n",
    "\n",
    "if 'student_qatlite_fp32' in models_for_bench:\n",
    "    lg, lb = collect_logits_labels(models_for_bench['student_qatlite_fp32'], val_loader, device=torch.device('cpu'))\n",
    "    metrics_targets['student_qatlite_fp32'] = compute_classification_metrics(lg, lb, class_names)\n",
    "\n",
    "if 'student_qatlite_int8' in models_for_bench:\n",
    "    lg, lb = collect_logits_labels(models_for_bench['student_qatlite_int8'], val_loader, device=torch.device('cpu'))\n",
    "    metrics_targets['student_qatlite_int8'] = compute_classification_metrics(lg, lb, class_names)\n",
    "\n",
    "print('\\n=== Качество (val, CPU) ===')\n",
    "for tag, m in metrics_targets.items():\n",
    "    print_metrics(tag, m)"
   ],
   "id": "e3bbaaab3af8ab26"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
