{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T21:31:14.595375Z",
     "start_time": "2025-08-19T21:31:09.502427Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# python\n",
    "import os\n",
    "import io\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import timm\n",
    "\n",
    "# ---------- Пути/чекпоинты ----------\n",
    "ISIC_ROOT = os.path.join('data', 'ISIC')\n",
    "WEIGHTS_DIR = os.path.join('data', 'model_weights')\n",
    "RESULTS_DIR = os.path.join('data', 'results')\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "CKPTS = {\n",
    "    'DeiT-T FP32 (KD)': os.path.join(WEIGHTS_DIR, 'student_best.pth'),\n",
    "    'DeiT-T FP32 (KD+EMA)': os.path.join(WEIGHTS_DIR, 'student_best_ema.pth'),\n",
    "    'DeiT-T INT8 (PTQ)': os.path.join(WEIGHTS_DIR, 'student_best_int8.pth'),\n",
    "    'DeiT-T INT8 (KD+EMA+PTQ)': os.path.join(WEIGHTS_DIR, 'student_best_ema_int8.pth'),\n",
    "    'DeiT-T QAT-lite FP32': os.path.join(WEIGHTS_DIR, 'student_best_qatlite.pth'),\n",
    "    'DeiT-T QAT-lite INT8': os.path.join(WEIGHTS_DIR, 'student_best_qatlite_int8.pth'),\n",
    "}\n",
    "\n",
    "# ---------- Хелперы ----------\n",
    "def state_dict_size_mb(state_dict: dict) -> float:\n",
    "    buf = io.BytesIO()\n",
    "    torch.save(state_dict, buf)\n",
    "    return buf.tell() / (1024.0 * 1024.0)\n",
    "\n",
    "def count_params(m: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in m.parameters())\n",
    "\n",
    "def count_flops(model: nn.Module, img_size=224):\n",
    "    try:\n",
    "        from ptflops import get_model_complexity_info  # type: ignore\n",
    "    except Exception:\n",
    "        return None\n",
    "    m_eval = copy.deepcopy(model).eval().cpu()\n",
    "    with torch.no_grad():\n",
    "        macs, _ = get_model_complexity_info(\n",
    "            m_eval, (3, img_size, img_size),\n",
    "            as_strings=False, print_per_layer_stat=False\n",
    "        )\n",
    "    return int(macs * 2)  # FLOPs ~= 2 * MACs\n",
    "\n",
    "def to_int8_dynamic(fp32_model: nn.Module) -> nn.Module:\n",
    "    return torch.ao.quantization.quantize_dynamic(\n",
    "        copy.deepcopy(fp32_model), {nn.Linear}, dtype=torch.qint8\n",
    "    )\n",
    "\n",
    "# ---------- Классы/число классов ----------\n",
    "with open(os.path.join(ISIC_ROOT, 'labels.json'), 'r', encoding='utf-8') as f:\n",
    "    label2idx = json.load(f)\n",
    "num_classes = len(label2idx)\n",
    "\n",
    "# ---------- Эталонные FP32-архитектуры (для Params/FLOPs) ----------\n",
    "archs = {\n",
    "    'DeiT-T': timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes),\n",
    "    'ResNet-18': timm.create_model('resnet18', pretrained=False, num_classes=num_classes),\n",
    "    'MobileNetV3-L': timm.create_model('mobilenetv3_large_100', pretrained=False, num_classes=num_classes),\n",
    "    'ConvNeXt-T': timm.create_model('convnext_tiny', pretrained=False, num_classes=num_classes),\n",
    "}\n",
    "\n",
    "# Считаем Params/FLOPs один раз на FP32-архитектуре\n",
    "arch_stats = {}\n",
    "for name, m in archs.items():\n",
    "    p = count_params(m)\n",
    "    f = count_flops(m, img_size=224)  # может вернуть None, если нет ptflops\n",
    "    arch_stats[name] = {\n",
    "        'params_m': p / 1e6,\n",
    "        'flops_g': (f / 1e9 if f is not None else None),\n",
    "    }\n",
    "\n",
    "# ---------- Модели-строки для таблицы ----------\n",
    "rows_def = [\n",
    "    ('DeiT-T FP32 (KD)',                 'DeiT-T',          'ckpt'),\n",
    "    ('DeiT-T FP32 (KD+EMA)',             'DeiT-T',          'ckpt'),\n",
    "    ('DeiT-T INT8 (PTQ)',                'DeiT-T',          'ckpt_int8'),\n",
    "    ('DeiT-T INT8 (KD+EMA+PTQ)',         'DeiT-T',          'ckpt_int8'),\n",
    "    ('DeiT-T QAT-lite FP32',             'DeiT-T',          'ckpt'),\n",
    "    ('DeiT-T QAT-lite INT8',             'DeiT-T',          'ckpt_int8'),\n",
    "    ('ResNet-18 FP32',                   'ResNet-18',       'fp32_live'),\n",
    "    ('ResNet-18 INT8 (PTQ)',             'ResNet-18',       'int8_live'),\n",
    "    ('MobileNetV3-L FP32',               'MobileNetV3-L',   'fp32_live'),\n",
    "    ('MobileNetV3-L INT8 (PTQ)',         'MobileNetV3-L',   'int8_live'),\n",
    "    ('ConvNeXt-T FP32',                   'ConvNeXt-T',     'fp32_live'),\n",
    "    ('ConvNeXt-T INT8 (PTQ)',             'ConvNeXt-T',     'int8_live'),\n",
    "]\n",
    "\n",
    "# ---------- Подсчёт Size для каждой строки ----------\n",
    "def size_mb_for_row(row_name: str, arch_key: str, how: str) -> float:\n",
    "    # 1) Если есть соответствующий чекпоинт — считаем размер из него (как в ноутбуке)\n",
    "    if how.startswith('ckpt'):\n",
    "        ckpt_path = CKPTS.get(row_name, '')\n",
    "        if os.path.isfile(ckpt_path):\n",
    "            obj = torch.load(ckpt_path, map_location='cpu')\n",
    "            sd = obj['model'] if (isinstance(obj, dict) and 'model' in obj) else obj\n",
    "            return state_dict_size_mb(sd)\n",
    "        # если нет файла — fallback к live-модели\n",
    "        how = 'int8_live' if how == 'ckpt_int8' else 'fp32_live'\n",
    "\n",
    "    # 2) Живые модели: собираем и берём size у state_dict()\n",
    "    if how == 'fp32_live':\n",
    "        if arch_key == 'DeiT-T':\n",
    "            m = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "        elif arch_key == 'ResNet-18':\n",
    "            m = timm.create_model('resnet18', pretrained=False, num_classes=num_classes)\n",
    "        elif arch_key == 'MobileNetV3-L':\n",
    "            m = timm.create_model('mobilenetv3_large_100', pretrained=False, num_classes=num_classes)\n",
    "        elif arch_key == 'ConvNeXt-T':\n",
    "            m = timm.create_model('convnext_tiny', pretrained=False, num_classes=num_classes)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown arch_key: {arch_key}')\n",
    "        return state_dict_size_mb(m.state_dict())\n",
    "\n",
    "    if how == 'int8_live':\n",
    "        if arch_key == 'DeiT-T':\n",
    "            base = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes)\n",
    "        elif arch_key == 'ResNet-18':\n",
    "            base = timm.create_model('resnet18', pretrained=False, num_classes=num_classes)\n",
    "        elif arch_key == 'MobileNetV3-L':\n",
    "            base = timm.create_model('mobilenetv3_large_100', pretrained=False, num_classes=num_classes)\n",
    "        elif arch_key == 'ConvNeXt-T':\n",
    "            base = timm.create_model('convnext_tiny', pretrained=False, num_classes=num_classes)\n",
    "        else:\n",
    "            raise ValueError(f'Unknown arch_key: {arch_key}')\n",
    "        qmodel = to_int8_dynamic(base)\n",
    "        return state_dict_size_mb(qmodel.state_dict())\n",
    "\n",
    "    raise ValueError(f'Unknown how={how}')\n",
    "\n",
    "# Собираем строки\n",
    "out_rows = []\n",
    "for disp_name, arch_key, how in rows_def:\n",
    "    s_mb = size_mb_for_row(disp_name, arch_key, how)\n",
    "    stats = arch_stats[arch_key]\n",
    "    out_rows.append({\n",
    "        'Model': disp_name,\n",
    "        'Params_M': round(stats['params_m'], 2),\n",
    "        'FLOPs_G@224': (round(stats['flops_g'], 2) if stats['flops_g'] is not None else None),\n",
    "        'Size_MB': round(s_mb, 2),\n",
    "    })\n",
    "\n",
    "# ---------- Сохраняем CSV ----------\n",
    "csv_path = os.path.join(RESULTS_DIR, 'models_desc.csv')\n",
    "pd.DataFrame(out_rows).to_csv(csv_path, index=False)\n",
    "print(f'CSV -> {csv_path}')\n"
   ],
   "id": "fd2b058676b74ca6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amirn\\PycharmProjects\\DS_builder\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\amirn\\PycharmProjects\\DS_builder\\.venv\\Lib\\site-packages\\torch\\_utils.py:425: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV -> data\\results\\models_desc.csv\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a69698c9f2795f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
